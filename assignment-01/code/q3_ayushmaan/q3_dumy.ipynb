{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_directory = 'saved_models'\n",
    "model_filename = 'linear_regression_model.pth'\n",
    "model_file_path = os.path.join(model_directory, model_filename)\n",
    "\n",
    "# Ensure the directory exists, create it if it doesn't\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "# Function to load or initialize the model\n",
    "def load_or_initialize_model(X_train, y_train):\n",
    "\n",
    "    # Load the model if it exists, otherwise initialize a new model\n",
    "\n",
    "    if 0 and os.path.exists(model_file_path):\n",
    "        print('Model exist so using it')\n",
    "        model = torch.load(model_file_path)\n",
    "    else:\n",
    "        print('Model does not exist so initialising from scratch')\n",
    "        input_size = X_train.shape[1]\n",
    "        model = nn.Linear(input_size, 1).double()\n",
    "        torch.save(model, model_file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the model\n",
    "def modeltrain(X_train, y_train, l2_lambda=0.01):  # Specify the regularization strength (lambda)\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "    model = nn.Linear(input_size, 1).double()  # Double data type for weight tensor\n",
    "\n",
    "    # Define loss function and optimizer with L2 regularization\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=l2_lambda)  # Adding weight decay for L2 regularization\n",
    "\n",
    "    # Train the model (rest of the code remains the same)\n",
    "\n",
    "    \n",
    "    num_epochs = 1000\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train.double())  # Ensure input data type matches model's weight data type\n",
    "        loss = criterion(outputs, y_train.view(-1, 1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    print('Training Done')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test the model\n",
    "predictions=''\n",
    "y_test=''\n",
    "def modeltest(X_test,y_1,model):\n",
    "    global predictions\n",
    "    global y_test\n",
    "    y_test=y_1\n",
    "    print(\"Testing starting\")\n",
    "    # Assuming 'model' is your trained linear regression model\n",
    "    # print(model)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)\n",
    "\n",
    "\n",
    "    print('testing over now accuracy analysis')\n",
    "    # print(predictions)\n",
    "    correct_pred=0\n",
    "    for i in range(len(predictions)):\n",
    "        if(abs(predictions[i]-y_test[i])<0.1):\n",
    "            correct_pred+=1\n",
    "    mean_accuracy=(correct_pred/len(predictions))*100\n",
    "    print(f'Percentage Accuracy: {mean_accuracy:.2f}%')\n",
    "\n",
    "    # for (int)\n",
    "    # Calculate the mean of the actual target values\n",
    "    mean_actual = torch.mean(y_test)\n",
    "\n",
    "    # Calculate the total sum of squares (TSS)\n",
    "    tss = torch.sum((y_test - mean_actual)**2)\n",
    "\n",
    "    # Calculate the residual sum of squares (RSS)\n",
    "    rss = torch.sum((y_test - predictions)**2)\n",
    "\n",
    "    # Calculate R-squared (R2)\n",
    "    r2 = 1 - (rss / tss)\n",
    "    print(\"r2 score is \",r2)\n",
    "\n",
    "    # Calculate MAE and MSE\n",
    "    # mae = mean_absolute_error(y_test, predictions)\n",
    "    # mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # print(f'MAE: {mae}')\n",
    "    # print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_plot(X,y):\n",
    "    # Replace 'X1' with the name of the feature you want to plot.\n",
    "    # n=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "    # n1=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "    # n2=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "\n",
    "    feature_to_plot = X[:,0] \n",
    "    feature_to_plot1 = X[:,1] \n",
    "    feature_to_plot2 = X[:,2] \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Create a scatter plotc.ear\n",
    "    # plt.scatter(feature_to_plot, y, alpha=0.5)\n",
    "    # plt.show()\n",
    "    plt.scatter(feature_to_plot1, y, alpha=0.5)\n",
    "    # plt.show()\n",
    "    plt.scatter(feature_to_plot2, y, alpha=0.5)\n",
    "\n",
    "    # plt.plot(feature_to_plot, y, alpha=0.5)  #line plot\n",
    "    plt.xlabel('Feature No:')  # Replace with the appropriate feature name\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Line Plot of Feature vs. y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data  proccessing and normalisation tried\n",
    "\n",
    "df = pd.read_csv('Q3_complex_linear_regression_dataset.csv')\n",
    "#print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Separate the target variable 'y' from the input features.\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding.\n",
    "X = pd.get_dummies(X, columns=['X3'], prefix=['X3'])\n",
    "\n",
    "for column in X.columns:\n",
    "    try:\n",
    "        X[column] = X[column].astype(float)\n",
    "    except ValueError:\n",
    "        print(f\"Column '{column}' cannot be converted to float.\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a PyTorch tensor.\n",
    "X = torch.tensor(X.values, dtype=torch.float64)\n",
    "list_X1=[]\n",
    "listd=[]\n",
    "for i in range(len(X)):\n",
    "    list_X1.append(X[i][0].item())\n",
    "    listd.append([X[i][0].item(),X[i][1].item(),X[i][2].item()])\n",
    "\n",
    "\n",
    "# print(list_X1)\n",
    "list_X1=torch.tensor(list_X1)\n",
    "mean_X1 = torch.mean(list_X1).item()\n",
    "std_X1 = torch.std(list_X1).item()\n",
    "# print(mean_X1.item(),std_X1.item())\n",
    "\n",
    "for i in range(len(X)):\n",
    "    listd[i][0]=(listd[i][0]-mean_X1)/std_X1\n",
    "listd=torch.tensor(listd)\n",
    "# print(\"X befor normalisation\",X)\n",
    "# X=listd\n",
    "# print('X after normalsation',X)\n",
    "\n",
    "# Convert the target variable to a PyTorch tensor.\n",
    "y = torch.tensor(y.values, dtype=torch.float64)\n",
    "size=len(X)\n",
    "train_ratio=0.7\n",
    "train_size=int(size*train_ratio)\n",
    "test_size=size-train_size\n",
    "\n",
    "\n",
    "#Splitting the data in training and testing data \n",
    "\n",
    "\n",
    "#Training data\n",
    "X_train=X[:train_size]\n",
    "y_train=y[:train_size]\n",
    "\n",
    "#Testing data\n",
    "X_test=X[train_size:]\n",
    "y_test=y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance between input1 and input2: 0.12740488844015435\n",
      "Covariance between input2 and input3: -0.025787961695156975\n",
      "Covariance between input3 and input2: 0.012576896787423134\n"
     ]
    }
   ],
   "source": [
    "#Relation of input variables with each other (EDA)\n",
    "input1=[]\n",
    "input2=[]\n",
    "input3=[]\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    c=X_train[i][0]\n",
    "\n",
    "    input1.append(c.item())\n",
    "    c=X_train[i][1]\n",
    "\n",
    "    input2.append(c.item())\n",
    "    c=X_train[i][2]\n",
    "    input3.append(c.item())\n",
    "\n",
    "covariance_matrix = np.cov(input1, input2)\n",
    "\n",
    "# Extract the covariance between the two variables from the covariance matrix\n",
    "covariance = covariance_matrix[0, 1]\n",
    "\n",
    "# print(\"Covariance between input1 and input2:\", covariance)\n",
    "\n",
    "covariance_matrix1 = np.cov(input1, input3)\n",
    "covariance_matrix2 = np.cov(input3, input2)\n",
    "covariance1 = covariance_matrix1[0, 1]\n",
    "covariance2 = covariance_matrix2[0, 1]\n",
    "print(\"Covariance between input1 and input2:\", covariance)\n",
    "print(\"Covariance between input2 and input3:\", covariance1)\n",
    "print(\"Covariance between input3 and input2:\", covariance2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model does not exist so initialising from scratch\n",
      "Epoch [100/1000], Loss: 4.141375067378297\n",
      "Epoch [200/1000], Loss: 4.003931521926671\n",
      "Epoch [300/1000], Loss: 3.942616421426183\n",
      "Epoch [400/1000], Loss: 3.9140671783272083\n",
      "Epoch [500/1000], Loss: 3.900372975874568\n",
      "Epoch [600/1000], Loss: 3.8936290703821776\n",
      "Epoch [700/1000], Loss: 3.890214256853382\n",
      "Epoch [800/1000], Loss: 3.8884301308890565\n",
      "Epoch [900/1000], Loss: 3.887464927048166\n",
      "Epoch [1000/1000], Loss: 3.8869231149382335\n",
      "Training Done\n",
      "Testing starting\n",
      "testing over now accuracy analysis\n",
      "Percentage Accuracy: 4.44%\n",
      "r2 score is  tensor(-174.1296, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# create_plot(X_train,y_train)\n",
    "# model = load_or_initialize_model(X_train, y_train)\n",
    "# model=modeltrain(X_train,y_train)\n",
    "model = load_or_initialize_model(X_train,y_train)\n",
    "model = modeltrain(X_train, y_train, l2_lambda=0.01)  # You can adjust the regularization st\n",
    "modeltest(X_test,y_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "31.216983758626668\n",
      "32.266406881190946\n",
      "[32.11499355  8.5740621  19.99559605  7.90661896  0.52053115 22.97444103\n",
      "  9.63221423 13.37936278 17.79834864 25.18626156]\n",
      "[34.22944283 10.29024283 20.90358031  6.53283796 -1.13345215 22.74013029\n",
      " 12.53363921 12.05232975 14.18387843 26.33137223]\n",
      "r2 score is  tensor(0.9605, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(type(predictions[0]))\n",
    "len(predictions)\n",
    "n=len(y_test)\n",
    "k=0\n",
    "\n",
    "\n",
    "# x=predictions\n",
    "x = np.array([scalar.item() for scalar in predictions])\n",
    "y=y_test\n",
    "y = np.array([scalar.item() for scalar in y_test])\n",
    "print(x[89])\n",
    "\n",
    "print(y[89])\n",
    "\n",
    "print(x[:10])\n",
    "print(y[:10])\n",
    "\n",
    "x=torch.tensor(x)\n",
    "y=torch.tensor(y)\n",
    "mean_actual = torch.mean(y)\n",
    "\n",
    "# Calculate the total sum of squares (TSS)\n",
    "tss = torch.sum((y - mean_actual)**2)\n",
    "\n",
    "# Calculate the residual sum of squares (RSS)\n",
    "rss = torch.sum((y - x)**2)\n",
    "\n",
    "# Calculate R-squared (R2)\n",
    "r2 = 1 - (rss / tss)\n",
    "print(\"r2 score is \",r2)\n",
    "\n",
    "# flag=0\n",
    "# num=int(input(\"\\nenter number of values : \\t\"))\n",
    "# while (num!=0):\n",
    "#     print(\"prediction | actual\")\n",
    "#     for i in range (num):\n",
    "#         print(round(x[k],3),end='\\t')\n",
    "#         print(round(y[k],3))\n",
    "#         k+=1\n",
    "#         if (k==n):\n",
    "#             flag=1\n",
    "#             break\n",
    "        \n",
    "#     if (flag==1):\n",
    "#         print('ended')\n",
    "#         break\n",
    "    # num=int(input(\"\\nenter number of values : \\t\"))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
