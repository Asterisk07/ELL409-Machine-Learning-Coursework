{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ed3c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:47.673682Z",
     "iopub.status.busy": "2023-09-08T23:56:47.673682Z",
     "iopub.status.idle": "2023-09-08T23:56:51.092741Z",
     "shell.execute_reply": "2023-09-08T23:56:51.092741Z"
    },
    "papermill": {
     "duration": 3.42617,
     "end_time": "2023-09-08T23:56:51.092741",
     "exception": false,
     "start_time": "2023-09-08T23:56:47.666571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab12aafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:51.102798Z",
     "iopub.status.busy": "2023-09-08T23:56:51.102798Z",
     "iopub.status.idle": "2023-09-08T23:56:51.106719Z",
     "shell.execute_reply": "2023-09-08T23:56:51.106719Z"
    },
    "papermill": {
     "duration": 0.008447,
     "end_time": "2023-09-08T23:56:51.106719",
     "exception": false,
     "start_time": "2023-09-08T23:56:51.098272",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "tuning_type='optimzer_name'\n",
    "learning_rate=0.5\n",
    "reduceLR_factor=0.1\n",
    "reduceLR_patience=5\n",
    "\n",
    "weight_decay_rate=0.01\n",
    "batchSize=128\n",
    "optimizer_name='SGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded79992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:51.114568Z",
     "iopub.status.busy": "2023-09-08T23:56:51.111562Z",
     "iopub.status.idle": "2023-09-08T23:56:51.117061Z",
     "shell.execute_reply": "2023-09-08T23:56:51.117061Z"
    },
    "papermill": {
     "duration": 0.007295,
     "end_time": "2023-09-08T23:56:51.118027",
     "exception": false,
     "start_time": "2023-09-08T23:56:51.110732",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "optimizer_name = \"RMSprop\"\n",
    "tuning_type = \"optimizer_name\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252a2f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:51.122970Z",
     "iopub.status.busy": "2023-09-08T23:56:51.122970Z",
     "iopub.status.idle": "2023-09-08T23:56:51.129565Z",
     "shell.execute_reply": "2023-09-08T23:56:51.129565Z"
    },
    "papermill": {
     "duration": 0.010186,
     "end_time": "2023-09-08T23:56:51.130906",
     "exception": false,
     "start_time": "2023-09-08T23:56:51.120720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# editable parameters\n",
    "quesname='q1/'\n",
    "\n",
    "# batchSize=64\n",
    "savename='q1/'\n",
    "\n",
    "# learning_rate=0.01\n",
    "# reduceLR_factor=0.5\n",
    "# reduceLR_patience=5\n",
    "\n",
    "# logfilename=f\n",
    "\n",
    "# accuracy=0\n",
    "# placeholder\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def loginfo(converged=False,testnum=1):     \n",
    "    \n",
    "    # logging.info(f\"\\nTest {testnum}\")\n",
    "    # logging.info(f\"initial learning rate : {learning_rate:.2f} \")\n",
    "    # logging.info(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    # # logging.info(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    # logging.info(f\"Number of epochs to converge: {num_epochs:.2f} \")\n",
    "    print(\"jeref\")\n",
    "    logging.basicConfig(filename=tuning_type+'.log', level=logging.INFO, format='%(message)s')\n",
    "    logging.info(f\"tuning : {tuning_type}\")\n",
    "    logging.info(  f\"Accuracy: {accuracy:.2f}% | epochs: {num_epochs} | initial learning rate: {learning_rate:.2f} | LR factor: {reduceLR_factor} | Patience: {reduceLR_patience} | weight decay rate: {weight_decay_rate} | Batchsize: {batchSize} | optimizer: {optimizer_name} | training time: {round(training_time,1)} sec\\n\")\n",
    "    # logging.info(f\"reduceLR_factor: {reduceLR_factor:.2f} \")\n",
    "    # logging.info(f\"reduceLR_patience : {reduceLR_patience:.2f} \")\n",
    "\n",
    "    # logging.info(f\"Test Session Finished \\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced74abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:51.138305Z",
     "iopub.status.busy": "2023-09-08T23:56:51.138305Z",
     "iopub.status.idle": "2023-09-08T23:56:51.943903Z",
     "shell.execute_reply": "2023-09-08T23:56:51.943903Z"
    },
    "papermill": {
     "duration": 0.811607,
     "end_time": "2023-09-08T23:56:51.944923",
     "exception": false,
     "start_time": "2023-09-08T23:56:51.133316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "import numpy as np\n",
    "import math\n",
    "import torch as t\n",
    "import torch \n",
    "import os\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import logging\n",
    "\n",
    "log_dir = '../../log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_dir=os.path.join(log_dir, quesname)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# logging.basicConfig(filename=logfile, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c914208",
   "metadata": {
    "papermill": {
     "duration": 0.002208,
     "end_time": "2023-09-08T23:56:51.953218",
     "exception": false,
     "start_time": "2023-09-08T23:56:51.951010",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f73c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:51.968289Z",
     "iopub.status.busy": "2023-09-08T23:56:51.968289Z",
     "iopub.status.idle": "2023-09-08T23:56:52.104235Z",
     "shell.execute_reply": "2023-09-08T23:56:52.104235Z"
    },
    "papermill": {
     "duration": 0.143141,
     "end_time": "2023-09-08T23:56:52.105444",
     "exception": false,
     "start_time": "2023-09-08T23:56:51.962303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# part 1 and 2:\n",
    "# dataset loading:\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../../data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor() # Normalisation step\n",
    "    \n",
    ")\n",
    "\n",
    "# note that ToTensor not just converts the image into a tensor but also normalises its intensity in range 0 to 1\n",
    "\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../../data/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor() # Normalisation step\n",
    ")\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batchSize, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db517a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:52.116679Z",
     "iopub.status.busy": "2023-09-08T23:56:52.116679Z",
     "iopub.status.idle": "2023-09-08T23:56:52.143739Z",
     "shell.execute_reply": "2023-09-08T23:56:52.143739Z"
    },
    "papermill": {
     "duration": 0.033093,
     "end_time": "2023-09-08T23:56:52.143739",
     "exception": false,
     "start_time": "2023-09-08T23:56:52.110646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint file '../../saved_models/q1/ignore.pth' not found. Model not loaded.\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "# part 3:\n",
    "\n",
    "\n",
    "\n",
    "# builtin classifier:\n",
    "\n",
    "# Define the model\n",
    "\n",
    "# model saving\n",
    "# Define a directory to save models\n",
    "save_dir = '../../saved_models/'\n",
    "save_dir=os.path.join(save_dir, savename)\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "\n",
    "    # we need to flatten the input data from 2d tensor into 1d tensor of 784 values (28*28) since data is in form of images\n",
    "    nn.Flatten(),  # Flatten the input data\n",
    "\n",
    "    nn.Linear(in_features=784, out_features=10),  # Linear layer   \n",
    "    # nn.Linear(in_features=784, out_features=batchSize),  # Linear layer   \n",
    "\n",
    "    nn.BatchNorm1d(10),\n",
    "    # this normalsises input tensors by scaling and shifting\n",
    "    # makes mean 0 and variance 1\n",
    "\n",
    "    # softmax function, or normalized exponential function converts a vector of K real numbers into a probability distribution of K possible outcomes\n",
    "    nn.Softmax(dim=1)  # Softmax activation\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "# Specify the path to the saved checkpoint file\n",
    "# model_path = '../../saved_models/model_checkpoint.pth'\n",
    "\n",
    "# tk\n",
    "model_path = os.path.join(save_dir, 'ignore.pth')\n",
    "\n",
    "# model_path = os.path.join(save_dir, 'model_checkpoint.pth')\n",
    "\n",
    "# Check if the file exists before loading\n",
    "if os.path.exists(model_path):\n",
    "    # Load the model checkpoint\n",
    "    checkpoint = torch.load(model_path)\n",
    "\n",
    "    # Load the model's state_dict\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Checkpoint file '{model_path}' not found. Model not loaded.\")\n",
    "\n",
    "# custom made classifier\n",
    "'''\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "\n",
    "        # Define the linear layer\n",
    "        # we used 28*28 input and 10 labels because we are working with MNIST database\n",
    "        self.fc = nn.Linear(28 * 28, 10)  # 28*28 input features, 10 output classes\n",
    "        \n",
    "        # Define an activation function (e.g., softmax for classification)\n",
    "\n",
    "        # softmax function, or normalized exponential function converts a vector of K real numbers into a probability distribution of K possible outcomes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    #IMPORTANT the name 'forward' is not arbitrary; it's a convention in PyTorch, and this method is automatically called when we pass data through our model.\n",
    "    def forward(self, x):\n",
    "\n",
    "        # we need to flatten the input data from 2d tensor into 1d tensor of 784 values (28*28) since data is in form of images\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
    "\n",
    "        x = self.fc(x)  # Apply the linear transformation\n",
    "        x = self.softmax(x) # Apply the activation function\n",
    "        return x\n",
    "'''\n",
    "print('model created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e347817a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:52.156421Z",
     "iopub.status.busy": "2023-09-08T23:56:52.155414Z",
     "iopub.status.idle": "2023-09-08T23:56:52.210486Z",
     "shell.execute_reply": "2023-09-08T23:56:52.210486Z"
    },
    "papermill": {
     "duration": 0.059942,
     "end_time": "2023-09-08T23:56:52.210486",
     "exception": false,
     "start_time": "2023-09-08T23:56:52.150544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure before training:  Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Softmax(dim=1)\n",
      ") \n",
      "\n",
      "\n",
      "Layer: 1.weight | Size: torch.Size([10, 784]) | Values : tensor([[ 0.0092, -0.0326, -0.0322,  ..., -0.0320,  0.0035,  0.0232],\n",
      "        [-0.0301,  0.0318, -0.0028,  ...,  0.0012,  0.0237, -0.0175]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 1.bias | Size: torch.Size([10]) | Values : tensor([0.0181, 0.0294], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.weight | Size: torch.Size([10]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.bias | Size: torch.Size([10]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure before training: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29383241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:52.224951Z",
     "iopub.status.busy": "2023-09-08T23:56:52.224951Z",
     "iopub.status.idle": "2023-09-08T23:56:52.229389Z",
     "shell.execute_reply": "2023-09-08T23:56:52.229389Z"
    },
    "papermill": {
     "duration": 0.013892,
     "end_time": "2023-09-08T23:56:52.232515",
     "exception": false,
     "start_time": "2023-09-08T23:56:52.218623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the optimizer based on the provided name, learning rate, and weight decay rate\n",
    "if optimizer_name == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay_rate)\n",
    "elif optimizer_name == \"Adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_rate)\n",
    "elif optimizer_name == \"RMSprop\":\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay_rate)\n",
    "else:\n",
    "    raise ValueError(\"Invalid optimizer name\")\n",
    "# type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee59b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:52.243716Z",
     "iopub.status.busy": "2023-09-08T23:56:52.243716Z",
     "iopub.status.idle": "2023-09-08T23:56:52.251864Z",
     "shell.execute_reply": "2023-09-08T23:56:52.251864Z"
    },
    "papermill": {
     "duration": 0.014956,
     "end_time": "2023-09-08T23:56:52.251864",
     "exception": false,
     "start_time": "2023-09-08T23:56:52.236908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 4 done\n"
     ]
    }
   ],
   "source": [
    "# part 4:\n",
    "\n",
    "# Define the loss function\n",
    "\n",
    "\n",
    "# import torch.optim as optim\n",
    "# Define the optimizer (e.g., SGD)\n",
    "\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "about SGD: Stochastic Gradient Descent:\n",
    "basically it performs seqeuntial updation of paramters after each epoch, using formula :\n",
    "parameter = parameter - learning_rate * gradient\n",
    "\n",
    "'''\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=reduceLR_factor, patience=reduceLR_patience, verbose=True)\n",
    "\n",
    "'''\n",
    "here mode = min : means reduce (instead of increase) LR when error plateaus\n",
    "\n",
    "patience = how many epochs to wait before reducing LR\n",
    "'''\n",
    "\n",
    "print('part 4 done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb621e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:56:52.270809Z",
     "iopub.status.busy": "2023-09-08T23:56:52.270809Z",
     "iopub.status.idle": "2023-09-08T23:59:00.914176Z",
     "shell.execute_reply": "2023-09-08T23:59:00.912789Z"
    },
    "papermill": {
     "duration": 128.652566,
     "end_time": "2023-09-08T23:59:00.916486",
     "exception": false,
     "start_time": "2023-09-08T23:56:52.263920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] - Loss: 2.3131, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] - Loss: 2.3251, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] - Loss: 2.3248, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] - Loss: 2.3248, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] - Loss: 2.3243, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] - Loss: 2.3247, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-02.\n",
      "Epoch [7/10] - Loss: 2.3250, Learning Rate: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] - Loss: 1.9908, Learning Rate: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] - Loss: 1.9895, Learning Rate: 0.050000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] - Loss: 1.9881, Learning Rate: 0.050000\n",
      "Training complete\n",
      "time taken to train :  127.94024348258972\n",
      "time per epoch :  12.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# part 5\n",
    "# Define the number of training epochs\n",
    "\n",
    "\n",
    "import time\n",
    "t1=time.time()\n",
    "# Training loop\n",
    "fig, ax1 = plt.subplots()\n",
    "# running_loss_data=[]\n",
    "converged=False\n",
    "avg_loss_data=[]\n",
    "LR_data=[]\n",
    "epoch_data=[]\n",
    "# plt.ion()\n",
    "# epoch_data=np.arange(1, num_epochs+1)\n",
    "# num_epochs=10\n",
    "plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "# plt.xlim(0, num_epochs+1)\n",
    "\n",
    "plt.legend()\n",
    "try:\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over the training dataset\n",
    "        for inputs, labels in train_loader:  # Replace train_loader with your data loader\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model's parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track the running loss\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate and print the average loss for this epoch\n",
    "        average_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # running_loss_data.append(running_loss)\n",
    "        avg_loss_data.append(average_loss)\n",
    "        epoch_data.append(epoch+1)\n",
    "        LR_data.append(current_lr)\n",
    "\n",
    "        # ax1.clear()\n",
    "    \n",
    "        # Plot the data for this epoch\n",
    "        # ax1.plot(epoch_data, avg_loss_data, label='Average Loss', color='blue')\n",
    "        # ax1.set_xlabel('Epoch')\n",
    "        # ax1.set_ylabel('Average Loss', color='blue')\n",
    "        \n",
    "        # ax2 = ax1.twinx()\n",
    "        # ax2.plot(epoch_data, LR_data, label='Learning Rate', color='red')\n",
    "        # ax2.set_ylabel('Learning Rate', color='red')\n",
    "        \n",
    "        # # Display the updated plot for this epoch\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.01)  # Adjust the pause duration as needed\n",
    "        \n",
    "        \n",
    "\n",
    "        # Update the learning rate scheduler with the training loss\n",
    "        scheduler.step(average_loss)\n",
    "        \n",
    "        # ax1.xticks(epoch_data,epoch_data)\n",
    "        # i=epoch\n",
    "        # ax1.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],2)}', ha='center', va='top')\n",
    "\n",
    "        # ax1.clear()\n",
    "    \n",
    "        # # Plot the data for this epoch\n",
    "        # ax1.plot(epoch_data, avg_loss_data, label='Average Loss', color='blue')\n",
    "        # ax1.set_xlabel('Epoch')\n",
    "        # ax1.set_ylabel('Average Loss', color='blue')\n",
    "        \n",
    "        # ax2 = ax1.twinx()\n",
    "        # ax2.plot(epoch_data, LR_data, label='Learning Rate', color='red')\n",
    "        # ax2.set_ylabel('Learning Rate', color='red')\n",
    "        \n",
    "        # # Display the updated plot for this epoch\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.01)\n",
    "\n",
    "        # plt.clear()\n",
    "        # plt.xticks(epoch_data,epoch_data)\n",
    "        # plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "        # plt.plot(epoch_data,avg_loss_data, marker='o', linestyle='-', markersize=8, label='Loss', color='red')\n",
    "        # plt.plot(epoch_data,LR_data,  marker='s', linestyle='--', markersize=8, label='Learning rate', color='blue')\n",
    "        # plt.xticks(epoch_data,epoch_data)\n",
    "        # # i=epoch\n",
    "\n",
    "        # for i in range(0,epoch+1):\n",
    "        #     plt.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],5)}', ha='center', va='top')\n",
    "            \n",
    "        #     plt.text(epoch_data[i], LR_data[i]+0.2, f'{LR_data[i]}', ha='center', va='bottom')\n",
    "        # plt.show()\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.001)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {average_loss:.4f}, Learning Rate: {current_lr:.6f}\")\n",
    "        if current_lr==0:\n",
    "            converged=True\n",
    "            print(\"training stopping\")\n",
    "            num_epochs=epoch+1\n",
    "            raise KeyboardInterrupt\n",
    "\n",
    "        \n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {average_loss:.4f}\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n ---------training interrupted----------- \\n\")\n",
    "\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "print(\"Training complete\")\n",
    "t2=time.time()\n",
    "training_time=t2-t1\n",
    "print('time taken to train : ',training_time)\n",
    "print('time per epoch : ',round(training_time/num_epochs,2))\n",
    "\n",
    "# pltfolder=f\"{learning_rate}|{num_epochs}|{reduceLR_factor}|{reduceLR_patience}\"\n",
    "\n",
    "# Add labels for each data point (y-values)\n",
    "for i in range(num_epochs):\n",
    "    plt.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],2)}', ha='center', va='top')\n",
    "    plt.text(epoch_data[i], LR_data[i]+0.2, f'{LR_data[i]}', ha='center', va='bottom')\n",
    "epoch_data=np.arange(1, num_epochs+1)\n",
    "plt.plot(epoch_data,avg_loss_data, marker='o', linestyle='-', markersize=8, label='Loss', color='red')\n",
    "plt.plot(epoch_data,LR_data,  marker='s', linestyle='--', markersize=8, label='Learning rate', color='blue')\n",
    "# plt.title(tunefilename)\n",
    "plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "plt.xlim(0, num_epochs+1)\n",
    "plt.xticks(epoch_data,epoch_data)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('')\n",
    "# plt.savefig()\n",
    "# plt.savefig('pat{reduceLR_patience}, LRfac{reduceLR_factor},LR{learning_rate}')\n",
    "# # print(plotfile)\n",
    "# plt.xticks(epoch_data,epoch_data)\n",
    "# plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "# plt.plot(epoch_data,avg_loss_data, marker='o', linestyle='-', markersize=8, label='Loss', color='red')\n",
    "# plt.plot(epoch_data,LR_data,  marker='s', linestyle='--', markersize=8, label='Learning rate', color='blue')\n",
    "# plt.xticks(epoch_data,epoch_data)\n",
    "# # i=epoch\n",
    "\n",
    "# for i in range(0,num_epochs):\n",
    "#     plt.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],5)}', ha='center', va='top')\n",
    "    \n",
    "#     plt.text(epoch_data[i], LR_data[i]+0.2, f'{LR_data[i]}', ha='center', va='bottom')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Save the model checkpoint to the specified directory\n",
    "# model_path = os.path.join(save_dir, 'model_checkpoint.pth')\n",
    "\n",
    "# tk\n",
    "# torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f86a526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:59:00.932387Z",
     "iopub.status.busy": "2023-09-08T23:59:00.932387Z",
     "iopub.status.idle": "2023-09-08T23:59:00.942547Z",
     "shell.execute_reply": "2023-09-08T23:59:00.942547Z"
    },
    "papermill": {
     "duration": 0.018685,
     "end_time": "2023-09-08T23:59:00.942547",
     "exception": false,
     "start_time": "2023-09-08T23:59:00.923862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure after training:  Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Softmax(dim=1)\n",
      ") \n",
      "\n",
      "\n",
      "jere\n",
      "Layer: 1.weight | Size: torch.Size([10, 784]) | Values : tensor([[-0.0246,  0.0271, -0.0331,  ..., -0.0177, -0.0084, -0.0138],\n",
      "        [ 0.0252,  0.0249,  0.0291,  ..., -0.0026, -0.0147, -0.0113]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 1.bias | Size: torch.Size([10]) | Values : tensor([-0.0257,  0.0260], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.weight | Size: torch.Size([10]) | Values : tensor([ 1.7815, -1.6172], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.bias | Size: torch.Size([10]) | Values : tensor([ 0.2565, -0.1054], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure after training: \", model, \"\\n\\n\")\n",
    "print(\"jere\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ad97a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:59:00.958660Z",
     "iopub.status.busy": "2023-09-08T23:59:00.958660Z",
     "iopub.status.idle": "2023-09-08T23:59:03.118702Z",
     "shell.execute_reply": "2023-09-08T23:59:03.118107Z"
    },
    "papermill": {
     "duration": 2.168039,
     "end_time": "2023-09-08T23:59:03.118702",
     "exception": false,
     "start_time": "2023-09-08T23:59:00.950663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 53.12%\n",
      "Accuracy till now:  testing dataset: 53.12%\n",
      "Accuracy on this batch 54.69%\n",
      "Accuracy till now:  testing dataset: 53.91%\n",
      "Accuracy on this batch 54.69%\n",
      "Accuracy till now:  testing dataset: 54.17%\n",
      "Accuracy on this batch 50.00%\n",
      "Accuracy till now:  testing dataset: 53.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 40.62%\n",
      "Accuracy till now:  testing dataset: 50.62%\n",
      "Accuracy on this batch 51.56%\n",
      "Accuracy till now:  testing dataset: 50.78%\n",
      "Accuracy on this batch 57.03%\n",
      "Accuracy till now:  testing dataset: 51.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 46.88%\n",
      "Accuracy till now:  testing dataset: 51.07%\n",
      "Accuracy on this batch 50.00%\n",
      "Accuracy till now:  testing dataset: 50.95%\n",
      "Accuracy on this batch 52.34%\n",
      "Accuracy till now:  testing dataset: 51.09%\n",
      "Accuracy on this batch 60.16%\n",
      "Accuracy till now:  testing dataset: 51.92%\n",
      "Accuracy on this batch 54.69%\n",
      "Accuracy till now:  testing dataset: 52.15%\n",
      "Accuracy on this batch 51.56%\n",
      "Accuracy till now:  testing dataset: 52.10%\n",
      "Accuracy on this batch 47.66%\n",
      "Accuracy till now:  testing dataset: 51.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 59.38%\n",
      "Accuracy till now:  testing dataset: 52.29%\n",
      "Accuracy on this batch 46.88%\n",
      "Accuracy till now:  testing dataset: 51.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 46.88%\n",
      "Accuracy till now:  testing dataset: 51.65%\n",
      "Accuracy on this batch 53.12%\n",
      "Accuracy till now:  testing dataset: 51.74%\n",
      "Accuracy on this batch 57.03%\n",
      "Accuracy till now:  testing dataset: 52.01%\n",
      "Accuracy on this batch 48.44%\n",
      "Accuracy till now:  testing dataset: 51.84%\n",
      "Accuracy on this batch 58.59%\n",
      "Accuracy till now:  testing dataset: 52.16%\n",
      "Accuracy on this batch 60.16%\n",
      "Accuracy till now:  testing dataset: 52.52%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 43.75%\n",
      "Accuracy till now:  testing dataset: 52.14%\n",
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 52.08%\n",
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 52.03%\n",
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 51.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 52.34%\n",
      "Accuracy till now:  testing dataset: 52.00%\n",
      "Accuracy on this batch 56.25%\n",
      "Accuracy till now:  testing dataset: 52.15%\n",
      "Accuracy on this batch 52.34%\n",
      "Accuracy till now:  testing dataset: 52.16%\n",
      "Accuracy on this batch 47.66%\n",
      "Accuracy till now:  testing dataset: 52.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 57.03%\n",
      "Accuracy till now:  testing dataset: 52.17%\n",
      "Accuracy on this batch 51.56%\n",
      "Accuracy till now:  testing dataset: 52.15%\n",
      "Accuracy on this batch 48.44%\n",
      "Accuracy till now:  testing dataset: 52.04%\n",
      "Accuracy on this batch 50.00%\n",
      "Accuracy till now:  testing dataset: 51.98%\n",
      "Accuracy on this batch 56.25%\n",
      "Accuracy till now:  testing dataset: 52.10%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 61.72%\n",
      "Accuracy till now:  testing dataset: 52.37%\n",
      "Accuracy on this batch 50.00%\n",
      "Accuracy till now:  testing dataset: 52.30%\n",
      "Accuracy on this batch 48.44%\n",
      "Accuracy till now:  testing dataset: 52.20%\n",
      "Accuracy on this batch 54.69%\n",
      "Accuracy till now:  testing dataset: 52.26%\n",
      "Accuracy on this batch 45.31%\n",
      "Accuracy till now:  testing dataset: 52.09%\n",
      "Accuracy on this batch 56.25%\n",
      "Accuracy till now:  testing dataset: 52.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 57.03%\n",
      "Accuracy till now:  testing dataset: 52.31%\n",
      "Accuracy on this batch 49.22%\n",
      "Accuracy till now:  testing dataset: 52.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 45.31%\n",
      "Accuracy till now:  testing dataset: 52.08%\n",
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 52.05%\n",
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 52.02%\n",
      "Accuracy on this batch 46.09%\n",
      "Accuracy till now:  testing dataset: 51.89%\n",
      "Accuracy on this batch 47.66%\n",
      "Accuracy till now:  testing dataset: 51.81%\n",
      "Accuracy on this batch 49.22%\n",
      "Accuracy till now:  testing dataset: 51.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 42.19%\n",
      "Accuracy till now:  testing dataset: 51.56%\n",
      "Accuracy on this batch 57.81%\n",
      "Accuracy till now:  testing dataset: 51.69%\n",
      "Accuracy on this batch 46.88%\n",
      "Accuracy till now:  testing dataset: 51.59%\n",
      "Accuracy on this batch 49.22%\n",
      "Accuracy till now:  testing dataset: 51.55%\n",
      "Accuracy on this batch 44.53%\n",
      "Accuracy till now:  testing dataset: 51.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 50.00%\n",
      "Accuracy till now:  testing dataset: 51.39%\n",
      "Accuracy on this batch 48.44%\n",
      "Accuracy till now:  testing dataset: 51.34%\n",
      "Accuracy on this batch 52.34%\n",
      "Accuracy till now:  testing dataset: 51.36%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 51.35%\n",
      "Accuracy on this batch 47.66%\n",
      "Accuracy till now:  testing dataset: 51.28%\n",
      "Accuracy on this batch 50.78%\n",
      "Accuracy till now:  testing dataset: 51.28%\n",
      "Accuracy on this batch 56.25%\n",
      "Accuracy till now:  testing dataset: 51.36%\n",
      "Accuracy on this batch 55.47%\n",
      "Accuracy till now:  testing dataset: 51.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 50.00%\n",
      "Accuracy till now:  testing dataset: 51.40%\n",
      "Accuracy on this batch 55.47%\n",
      "Accuracy till now:  testing dataset: 51.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 49.22%\n",
      "Accuracy till now:  testing dataset: 51.43%\n",
      "Accuracy on this batch 62.50%\n",
      "Accuracy till now:  testing dataset: 51.60%\n",
      "Accuracy on this batch 59.38%\n",
      "Accuracy till now:  testing dataset: 51.71%\n",
      "Accuracy on this batch 53.91%\n",
      "Accuracy till now:  testing dataset: 51.75%\n",
      "Accuracy on this batch 57.81%\n",
      "Accuracy till now:  testing dataset: 51.83%\n",
      "Accuracy on this batch 53.91%\n",
      "Accuracy till now:  testing dataset: 51.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 53.12%\n",
      "Accuracy till now:  testing dataset: 51.88%\n",
      "Accuracy on this batch 44.53%\n",
      "Accuracy till now:  testing dataset: 51.78%\n",
      "Accuracy on this batch 48.44%\n",
      "Accuracy till now:  testing dataset: 51.73%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 55.47%\n",
      "Accuracy till now:  testing dataset: 51.78%\n",
      "Accuracy on this batch 53.91%\n",
      "Accuracy till now:  testing dataset: 51.81%\n",
      "Accuracy on this batch 51.56%\n",
      "Accuracy till now:  testing dataset: 51.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 61.72%\n",
      "Accuracy till now:  testing dataset: 51.94%\n",
      "Accuracy on this batch 54.69%\n",
      "Accuracy till now:  testing dataset: 51.97%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 62.50%\n",
      "Accuracy till now:  testing dataset: 51.99%\n",
      "\n",
      "number of tests: 79\n",
      "Accuracy on the testing dataset: 51.99%\n",
      "time taken to train :  127.94024348258972\n",
      "51.99\n",
      "jeref\n",
      "data saved\n"
     ]
    }
   ],
   "source": [
    "# part 6 :\n",
    "# testing \n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate over the testing dataset\n",
    "\n",
    "k=0\n",
    "for inputs, labels in test_loader:  # Use your test data loader\n",
    "    k+=1\n",
    "    # Forward pass to obtain predictions\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get the predicted class for each example in the batch\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    \n",
    "    # Count correct predictions in this batch\n",
    "    batch_correct_predictions = (predicted == labels).sum().item()\n",
    "    correct_predictions += batch_correct_predictions\n",
    "    \n",
    "    # Count total predictions in this batch\n",
    "\n",
    "    batch_total_predictions = labels.size(0)\n",
    "    total_predictions += batch_total_predictions \n",
    "\n",
    "    # Print the running accuracy for this batch\n",
    "    # Update running accuracy\n",
    "    batch_accuracy=batch_correct_predictions/batch_total_predictions * 100.0\n",
    "    print(f\"Accuracy on this batch {batch_accuracy:.2f}%\")\n",
    "\n",
    "    accuracy = (correct_predictions / total_predictions) * 100.0\n",
    "    print(f\"Accuracy till now:  testing dataset: {accuracy:.2f}%\")\n",
    "\n",
    "print()\n",
    "print(\"number of tests:\",k)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (correct_predictions / total_predictions) * 100.0\n",
    "print(f\"Accuracy on the testing dataset: {accuracy:.2f}%\")\n",
    "print('time taken to train : ',training_time)\n",
    "\n",
    "\n",
    "# saving accuracy\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "# tk\n",
    "# log_dir=\"../../log/\"\n",
    "# tunefilename=f'Accuracy {accuracy} ,pat{reduceLR_patience}, LRfac{reduceLR_factor},LR{learning_rate}'\n",
    "# plot_dir=log_dir\n",
    "# os.makedirs(plot_dir, exist_ok=True)\n",
    "# logfilename=tunefilename+'.log'\n",
    "# plotfilename=tunefilename+'.png'\n",
    "# plotfilename=f'pat{reduceLR_patience}, LRfac{reduceLR_factor},LR{learning_rate}.png'\n",
    "# plotfile=os.path.join(log_dir, plotfilename)\n",
    "# logfile=os.path.join(log_dir, logfilename)\n",
    "\n",
    "\n",
    "# tunefilename=f'patience={reduceLR_patience}_LR_factor={reduceLR_factor}'\n",
    "\n",
    "import logging\n",
    "\n",
    "# print(logfile)\n",
    "print(accuracy)\n",
    "# logging.basicConfig(filename=f'{accuracy}.log', level=logging.INFO, format='%(message)s')\n",
    "# logging.info(f\"initial learning rate : {learning_rate:.2f} | Accuracy: {accuracy:.2f}% | {num_epochs} epochs | converged : {converged}\\n\")\n",
    "# logging.info(\"ererer\")\n",
    "loginfo(accuracy)\n",
    "logging.shutdown()\n",
    "\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "# loginfo(converged,accuracy)\n",
    "print(\"data saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71df70ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T23:59:03.142351Z",
     "iopub.status.busy": "2023-09-08T23:59:03.142351Z",
     "iopub.status.idle": "2023-09-08T23:59:03.150150Z",
     "shell.execute_reply": "2023-09-08T23:59:03.149583Z"
    },
    "papermill": {
     "duration": 0.024335,
     "end_time": "2023-09-08T23:59:03.150150",
     "exception": false,
     "start_time": "2023-09-08T23:59:03.125815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loginfo(accuracy)\n",
    "# logging.shutdown()\n",
    "# logging.basicConfig(filename='new1'+'.log', level=logging.INFO, format='%(message)s')\n",
    "# logging\n",
    "\n",
    "# logging.info(\"hi\")\n",
    "# logging.info(f\"tuning : {tuning_type}\")\n",
    "# logging.info(  f\"Accuracy: {accuracy:.2f}% | epochs: {num_epochs} | initial learning rate: {learning_rate:.2f} | LR factor: {reduceLR_factor} | Patience: {reduceLR_patience} | weight decay rate: {weight_decay_rate} | Batchsize: {batchSize} | optimizer: {optimizer_name} | training time: {round(training_time,1)} sec\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 139.894491,
   "end_time": "2023-09-08T23:59:04.492793",
   "environment_variables": {},
   "exception": null,
   "input_path": "c:\\Users\\pande\\OneDrive\\Desktop\\code\\ML\\ELL409-Machine-Learning-Coursework\\assignment-01\\code\\q1linear-classification\\a5.ipynb",
   "output_path": "c:\\Users\\pande\\OneDrive\\Desktop\\code\\ML\\ELL409-Machine-Learning-Coursework\\assignment-01\\code\\q1linear-classification\\a5out.ipynb",
   "parameters": {
    "optimizer_name": "RMSprop",
    "tuning_type": "optimizer_name"
   },
   "start_time": "2023-09-08T23:56:44.598302",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}