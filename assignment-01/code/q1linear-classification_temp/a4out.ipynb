{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ed3c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:10.112519Z",
     "iopub.status.busy": "2023-09-08T22:37:10.112519Z",
     "iopub.status.idle": "2023-09-08T22:37:11.903701Z",
     "shell.execute_reply": "2023-09-08T22:37:11.903701Z"
    },
    "papermill": {
     "duration": 1.791182,
     "end_time": "2023-09-08T22:37:11.903701",
     "exception": false,
     "start_time": "2023-09-08T22:37:10.112519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab12aafe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:11.903701Z",
     "iopub.status.busy": "2023-09-08T22:37:11.903701Z",
     "iopub.status.idle": "2023-09-08T22:37:11.913136Z",
     "shell.execute_reply": "2023-09-08T22:37:11.913136Z"
    },
    "papermill": {
     "duration": 0.009435,
     "end_time": "2023-09-08T22:37:11.913136",
     "exception": false,
     "start_time": "2023-09-08T22:37:11.903701",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "reduceLR_factor=0.5\n",
    "reduceLR_patience=5\n",
    "weight_decay_rate=0.5\n",
    "batchSize=64\n",
    "tuning_type='learning_rate'\n",
    "optimizer_name='SGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70f6c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:11.919243Z",
     "iopub.status.busy": "2023-09-08T22:37:11.919243Z",
     "iopub.status.idle": "2023-09-08T22:37:11.922275Z",
     "shell.execute_reply": "2023-09-08T22:37:11.922275Z"
    },
    "papermill": {
     "duration": 0.009139,
     "end_time": "2023-09-08T22:37:11.922275",
     "exception": false,
     "start_time": "2023-09-08T22:37:11.913136",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.14\n",
    "reduceLR_factor = 0.6\n",
    "reduceLR_patience = 5\n",
    "weight_decay_rate = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "252a2f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:11.927379Z",
     "iopub.status.busy": "2023-09-08T22:37:11.927379Z",
     "iopub.status.idle": "2023-09-08T22:37:11.932716Z",
     "shell.execute_reply": "2023-09-08T22:37:11.932716Z"
    },
    "papermill": {
     "duration": 0.010441,
     "end_time": "2023-09-08T22:37:11.932716",
     "exception": false,
     "start_time": "2023-09-08T22:37:11.922275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# editable parameters\n",
    "quesname='q1/'\n",
    "\n",
    "# batchSize=64\n",
    "savename='q1/'\n",
    "\n",
    "# learning_rate=0.01\n",
    "# reduceLR_factor=0.5\n",
    "# reduceLR_patience=5\n",
    "\n",
    "# logfilename=f\n",
    "\n",
    "# accuracy=0\n",
    "# placeholder\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def loginfo(converged=False,testnum=1):     \n",
    "    \n",
    "    # logging.info(f\"\\nTest {testnum}\")\n",
    "    # logging.info(f\"initial learning rate : {learning_rate:.2f} \")\n",
    "    # logging.info(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    # # logging.info(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    # logging.info(f\"Number of epochs to converge: {num_epochs:.2f} \")\n",
    "    logging.basicConfig(filename=f'log.log', level=logging.INFO, format='%(message)s')\n",
    "    logging.info(f\"tuning : {tuning_type}\")\n",
    "    logging.info(  f\"Accuracy: {accuracy:.2f}% | epochs: {num_epochs} | initial learning rate: {learning_rate:.2f} | LR factor: {reduceLR_factor} | Patience: {reduceLR_patience} | weight decay rate: {weight_decay_rate} | Batchsize: {batchSize} | optimizer: {optimizer_name} | training time: {round(training_time,1)} sec\\n\")\n",
    "    # logging.info(f\"reduceLR_factor: {reduceLR_factor:.2f} \")\n",
    "    # logging.info(f\"reduceLR_patience : {reduceLR_patience:.2f} \")\n",
    "\n",
    "    # logging.info(f\"Test Session Finished \\n\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced74abf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:11.939970Z",
     "iopub.status.busy": "2023-09-08T22:37:11.939970Z",
     "iopub.status.idle": "2023-09-08T22:37:12.384523Z",
     "shell.execute_reply": "2023-09-08T22:37:12.384523Z"
    },
    "papermill": {
     "duration": 0.45015,
     "end_time": "2023-09-08T22:37:12.385979",
     "exception": false,
     "start_time": "2023-09-08T22:37:11.935829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "import numpy as np\n",
    "import math\n",
    "import torch as t\n",
    "import torch \n",
    "import os\n",
    "\n",
    "\n",
    "# import torch\n",
    "# import logging\n",
    "\n",
    "log_dir = '../../log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "log_dir=os.path.join(log_dir, quesname)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# logging.basicConfig(filename=logfile, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c914208",
   "metadata": {
    "papermill": {
     "duration": 0.000525,
     "end_time": "2023-09-08T22:37:12.389099",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.388574",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f73c15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:12.389099Z",
     "iopub.status.busy": "2023-09-08T22:37:12.389099Z",
     "iopub.status.idle": "2023-09-08T22:37:12.510111Z",
     "shell.execute_reply": "2023-09-08T22:37:12.510111Z"
    },
    "papermill": {
     "duration": 0.121012,
     "end_time": "2023-09-08T22:37:12.510111",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.389099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# part 1 and 2:\n",
    "# dataset loading:\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"../../data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor() # Normalisation step\n",
    "    \n",
    ")\n",
    "\n",
    "# note that ToTensor not just converts the image into a tensor but also normalises its intensity in range 0 to 1\n",
    "\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"../../data/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor() # Normalisation step\n",
    ")\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "\n",
    "\n",
    "train_loader = DataLoader(training_data, batch_size=batchSize, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db517a0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:12.519630Z",
     "iopub.status.busy": "2023-09-08T22:37:12.519630Z",
     "iopub.status.idle": "2023-09-08T22:37:12.528829Z",
     "shell.execute_reply": "2023-09-08T22:37:12.528829Z"
    },
    "papermill": {
     "duration": 0.018718,
     "end_time": "2023-09-08T22:37:12.528829",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.510111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint file '../../saved_models/q1/ignore.pth' not found. Model not loaded.\n",
      "model created\n"
     ]
    }
   ],
   "source": [
    "# part 3:\n",
    "\n",
    "\n",
    "\n",
    "# builtin classifier:\n",
    "\n",
    "# Define the model\n",
    "\n",
    "# model saving\n",
    "# Define a directory to save models\n",
    "save_dir = '../../saved_models/'\n",
    "save_dir=os.path.join(save_dir, savename)\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "\n",
    "    # we need to flatten the input data from 2d tensor into 1d tensor of 784 values (28*28) since data is in form of images\n",
    "    nn.Flatten(),  # Flatten the input data\n",
    "\n",
    "    nn.Linear(in_features=784, out_features=10),  # Linear layer   \n",
    "    # nn.Linear(in_features=784, out_features=batchSize),  # Linear layer   \n",
    "\n",
    "    nn.BatchNorm1d(10),\n",
    "    # this normalsises input tensors by scaling and shifting\n",
    "    # makes mean 0 and variance 1\n",
    "\n",
    "    # softmax function, or normalized exponential function converts a vector of K real numbers into a probability distribution of K possible outcomes\n",
    "    nn.Softmax(dim=1)  # Softmax activation\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "# Specify the path to the saved checkpoint file\n",
    "# model_path = '../../saved_models/model_checkpoint.pth'\n",
    "\n",
    "# tk\n",
    "model_path = os.path.join(save_dir, 'ignore.pth')\n",
    "\n",
    "# model_path = os.path.join(save_dir, 'model_checkpoint.pth')\n",
    "\n",
    "# Check if the file exists before loading\n",
    "if os.path.exists(model_path):\n",
    "    # Load the model checkpoint\n",
    "    checkpoint = torch.load(model_path)\n",
    "\n",
    "    # Load the model's state_dict\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    print(f\"Checkpoint file '{model_path}' not found. Model not loaded.\")\n",
    "\n",
    "# custom made classifier\n",
    "'''\n",
    "class LinearClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "\n",
    "        # Define the linear layer\n",
    "        # we used 28*28 input and 10 labels because we are working with MNIST database\n",
    "        self.fc = nn.Linear(28 * 28, 10)  # 28*28 input features, 10 output classes\n",
    "        \n",
    "        # Define an activation function (e.g., softmax for classification)\n",
    "\n",
    "        # softmax function, or normalized exponential function converts a vector of K real numbers into a probability distribution of K possible outcomes\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    #IMPORTANT the name 'forward' is not arbitrary; it's a convention in PyTorch, and this method is automatically called when we pass data through our model.\n",
    "    def forward(self, x):\n",
    "\n",
    "        # we need to flatten the input data from 2d tensor into 1d tensor of 784 values (28*28) since data is in form of images\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input tensor\n",
    "\n",
    "        x = self.fc(x)  # Apply the linear transformation\n",
    "        x = self.softmax(x) # Apply the activation function\n",
    "        return x\n",
    "'''\n",
    "print('model created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e347817a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:12.535344Z",
     "iopub.status.busy": "2023-09-08T22:37:12.535344Z",
     "iopub.status.idle": "2023-09-08T22:37:12.540903Z",
     "shell.execute_reply": "2023-09-08T22:37:12.540903Z"
    },
    "papermill": {
     "duration": 0.012074,
     "end_time": "2023-09-08T22:37:12.540903",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.528829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure before training:  Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Softmax(dim=1)\n",
      ") \n",
      "\n",
      "\n",
      "Layer: 1.weight | Size: torch.Size([10, 784]) | Values : tensor([[ 0.0037, -0.0076,  0.0141,  ..., -0.0269, -0.0048, -0.0292],\n",
      "        [ 0.0137, -0.0096, -0.0099,  ...,  0.0156,  0.0165,  0.0215]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 1.bias | Size: torch.Size([10]) | Values : tensor([0.0271, 0.0043], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.weight | Size: torch.Size([10]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.bias | Size: torch.Size([10]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure before training: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29383241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:12.540903Z",
     "iopub.status.busy": "2023-09-08T22:37:12.540903Z",
     "iopub.status.idle": "2023-09-08T22:37:12.552939Z",
     "shell.execute_reply": "2023-09-08T22:37:12.551858Z"
    },
    "papermill": {
     "duration": 0.012036,
     "end_time": "2023-09-08T22:37:12.552939",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.540903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the optimizer based on the provided name, learning rate, and weight decay rate\n",
    "if optimizer_name == \"SGD\":\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay_rate)\n",
    "elif optimizer_name == \"Adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_rate)\n",
    "elif optimizer_name == \"RMSprop\":\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay_rate)\n",
    "else:\n",
    "    raise ValueError(\"Invalid optimizer name\")\n",
    "# type(optimizer).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cee59b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:12.559963Z",
     "iopub.status.busy": "2023-09-08T22:37:12.559963Z",
     "iopub.status.idle": "2023-09-08T22:37:12.568032Z",
     "shell.execute_reply": "2023-09-08T22:37:12.568032Z"
    },
    "papermill": {
     "duration": 0.015093,
     "end_time": "2023-09-08T22:37:12.568032",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.552939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 4 done\n"
     ]
    }
   ],
   "source": [
    "# part 4:\n",
    "\n",
    "# Define the loss function\n",
    "\n",
    "\n",
    "# import torch.optim as optim\n",
    "# Define the optimizer (e.g., SGD)\n",
    "\n",
    "\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "about SGD: Stochastic Gradient Descent:\n",
    "basically it performs seqeuntial updation of paramters after each epoch, using formula :\n",
    "parameter = parameter - learning_rate * gradient\n",
    "\n",
    "'''\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=reduceLR_factor, patience=reduceLR_patience, verbose=True)\n",
    "\n",
    "'''\n",
    "here mode = min : means reduce (instead of increase) LR when error plateaus\n",
    "\n",
    "patience = how many epochs to wait before reducing LR\n",
    "'''\n",
    "\n",
    "print('part 4 done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcb621e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:12.575073Z",
     "iopub.status.busy": "2023-09-08T22:37:12.575073Z",
     "iopub.status.idle": "2023-09-08T22:37:24.353719Z",
     "shell.execute_reply": "2023-09-08T22:37:24.353719Z"
    },
    "papermill": {
     "duration": 11.786819,
     "end_time": "2023-09-08T22:37:24.354851",
     "exception": false,
     "start_time": "2023-09-08T22:37:12.568032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] - Loss: 1.7440, Learning Rate: 0.140000\n",
      "Training complete\n",
      "time taken to train :  11.49685287475586\n",
      "time per epoch :  11.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# part 5\n",
    "# Define the number of training epochs\n",
    "\n",
    "\n",
    "import time\n",
    "t1=time.time()\n",
    "# Training loop\n",
    "fig, ax1 = plt.subplots()\n",
    "# running_loss_data=[]\n",
    "converged=False\n",
    "avg_loss_data=[]\n",
    "LR_data=[]\n",
    "epoch_data=[]\n",
    "# plt.ion()\n",
    "# epoch_data=np.arange(1, num_epochs+1)\n",
    "# num_epochs=10\n",
    "plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "# plt.xlim(0, num_epochs+1)\n",
    "\n",
    "plt.legend()\n",
    "try:\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model in training mode\n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over the training dataset\n",
    "        for inputs, labels in train_loader:  # Replace train_loader with your data loader\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model's parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track the running loss\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate and print the average loss for this epoch\n",
    "        average_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # running_loss_data.append(running_loss)\n",
    "        avg_loss_data.append(average_loss)\n",
    "        epoch_data.append(epoch+1)\n",
    "        LR_data.append(current_lr)\n",
    "\n",
    "        # ax1.clear()\n",
    "    \n",
    "        # Plot the data for this epoch\n",
    "        # ax1.plot(epoch_data, avg_loss_data, label='Average Loss', color='blue')\n",
    "        # ax1.set_xlabel('Epoch')\n",
    "        # ax1.set_ylabel('Average Loss', color='blue')\n",
    "        \n",
    "        # ax2 = ax1.twinx()\n",
    "        # ax2.plot(epoch_data, LR_data, label='Learning Rate', color='red')\n",
    "        # ax2.set_ylabel('Learning Rate', color='red')\n",
    "        \n",
    "        # # Display the updated plot for this epoch\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.01)  # Adjust the pause duration as needed\n",
    "        \n",
    "        \n",
    "\n",
    "        # Update the learning rate scheduler with the training loss\n",
    "        scheduler.step(average_loss)\n",
    "        \n",
    "        # ax1.xticks(epoch_data,epoch_data)\n",
    "        # i=epoch\n",
    "        # ax1.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],2)}', ha='center', va='top')\n",
    "\n",
    "        # ax1.clear()\n",
    "    \n",
    "        # # Plot the data for this epoch\n",
    "        # ax1.plot(epoch_data, avg_loss_data, label='Average Loss', color='blue')\n",
    "        # ax1.set_xlabel('Epoch')\n",
    "        # ax1.set_ylabel('Average Loss', color='blue')\n",
    "        \n",
    "        # ax2 = ax1.twinx()\n",
    "        # ax2.plot(epoch_data, LR_data, label='Learning Rate', color='red')\n",
    "        # ax2.set_ylabel('Learning Rate', color='red')\n",
    "        \n",
    "        # # Display the updated plot for this epoch\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.01)\n",
    "\n",
    "        # plt.clear()\n",
    "        # plt.xticks(epoch_data,epoch_data)\n",
    "        # plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "        # plt.plot(epoch_data,avg_loss_data, marker='o', linestyle='-', markersize=8, label='Loss', color='red')\n",
    "        # plt.plot(epoch_data,LR_data,  marker='s', linestyle='--', markersize=8, label='Learning rate', color='blue')\n",
    "        # plt.xticks(epoch_data,epoch_data)\n",
    "        # # i=epoch\n",
    "\n",
    "        # for i in range(0,epoch+1):\n",
    "        #     plt.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],5)}', ha='center', va='top')\n",
    "            \n",
    "        #     plt.text(epoch_data[i], LR_data[i]+0.2, f'{LR_data[i]}', ha='center', va='bottom')\n",
    "        # plt.show()\n",
    "        # plt.draw()\n",
    "        # plt.pause(0.001)\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {average_loss:.4f}, Learning Rate: {current_lr:.6f}\")\n",
    "        if current_lr==0:\n",
    "            converged=True\n",
    "            print(\"training stopping\")\n",
    "            num_epochs=epoch+1\n",
    "            raise KeyboardInterrupt\n",
    "\n",
    "        \n",
    "        # print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {average_loss:.4f}\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n ---------training interrupted----------- \\n\")\n",
    "\n",
    "\n",
    "# plt.ioff()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "print(\"Training complete\")\n",
    "t2=time.time()\n",
    "training_time=t2-t1\n",
    "print('time taken to train : ',training_time)\n",
    "print('time per epoch : ',round(training_time/num_epochs,2))\n",
    "\n",
    "# pltfolder=f\"{learning_rate}|{num_epochs}|{reduceLR_factor}|{reduceLR_patience}\"\n",
    "\n",
    "# Add labels for each data point (y-values)\n",
    "for i in range(num_epochs):\n",
    "    plt.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],2)}', ha='center', va='top')\n",
    "    plt.text(epoch_data[i], LR_data[i]+0.2, f'{LR_data[i]}', ha='center', va='bottom')\n",
    "epoch_data=np.arange(1, num_epochs+1)\n",
    "plt.plot(epoch_data,avg_loss_data, marker='o', linestyle='-', markersize=8, label='Loss', color='red')\n",
    "plt.plot(epoch_data,LR_data,  marker='s', linestyle='--', markersize=8, label='Learning rate', color='blue')\n",
    "# plt.title(tunefilename)\n",
    "plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "plt.xlim(0, num_epochs+1)\n",
    "plt.xticks(epoch_data,epoch_data)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig('')\n",
    "# plt.savefig()\n",
    "# plt.savefig('pat{reduceLR_patience}, LRfac{reduceLR_factor},LR{learning_rate}')\n",
    "# # print(plotfile)\n",
    "# plt.xticks(epoch_data,epoch_data)\n",
    "# plt.title(f'LR = {learning_rate} ,  LRfac {reduceLR_factor},  pat {reduceLR_patience}')\n",
    "# plt.plot(epoch_data,avg_loss_data, marker='o', linestyle='-', markersize=8, label='Loss', color='red')\n",
    "# plt.plot(epoch_data,LR_data,  marker='s', linestyle='--', markersize=8, label='Learning rate', color='blue')\n",
    "# plt.xticks(epoch_data,epoch_data)\n",
    "# # i=epoch\n",
    "\n",
    "# for i in range(0,num_epochs):\n",
    "#     plt.text(epoch_data[i], avg_loss_data[i]-0.2, f'{round(avg_loss_data[i],5)}', ha='center', va='top')\n",
    "    \n",
    "#     plt.text(epoch_data[i], LR_data[i]+0.2, f'{LR_data[i]}', ha='center', va='bottom')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Save the model checkpoint to the specified directory\n",
    "# model_path = os.path.join(save_dir, 'model_checkpoint.pth')\n",
    "\n",
    "# tk\n",
    "# torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f86a526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:24.354851Z",
     "iopub.status.busy": "2023-09-08T22:37:24.354851Z",
     "iopub.status.idle": "2023-09-08T22:37:24.366893Z",
     "shell.execute_reply": "2023-09-08T22:37:24.366893Z"
    },
    "papermill": {
     "duration": 0.012042,
     "end_time": "2023-09-08T22:37:24.366893",
     "exception": false,
     "start_time": "2023-09-08T22:37:24.354851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure after training:  Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): Softmax(dim=1)\n",
      ") \n",
      "\n",
      "\n",
      "jere\n",
      "Layer: 1.weight | Size: torch.Size([10, 784]) | Values : tensor([[ 0.0037, -0.0076,  0.0143,  ..., -0.0518, -0.0143, -0.0305],\n",
      "        [ 0.0137, -0.0095, -0.0097,  ...,  0.0061,  0.0155,  0.0215]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 1.bias | Size: torch.Size([10]) | Values : tensor([0.0271, 0.0043], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.weight | Size: torch.Size([10]) | Values : tensor([2.4629, 2.5074], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: 2.bias | Size: torch.Size([10]) | Values : tensor([0.0561, 0.0213], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure after training: \", model, \"\\n\\n\")\n",
    "print(\"jere\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ad97a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-08T22:37:24.372982Z",
     "iopub.status.busy": "2023-09-08T22:37:24.372982Z",
     "iopub.status.idle": "2023-09-08T22:37:25.913411Z",
     "shell.execute_reply": "2023-09-08T22:37:25.913411Z"
    },
    "papermill": {
     "duration": 1.546518,
     "end_time": "2023-09-08T22:37:25.913411",
     "exception": false,
     "start_time": "2023-09-08T22:37:24.366893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 79.69%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 83.59%\n",
      "Accuracy on this batch 90.62%\n",
      "Accuracy till now:  testing dataset: 85.94%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 85.16%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 84.69%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 84.64%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 85.04%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 84.38%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 83.85%\n",
      "Accuracy on this batch 73.44%\n",
      "Accuracy till now:  testing dataset: 82.81%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 82.95%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 82.81%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 83.17%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 83.48%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 83.33%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 82.81%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 83.00%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 82.55%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 82.24%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 82.11%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 82.37%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 82.53%\n",
      "Accuracy on this batch 90.62%\n",
      "Accuracy till now:  testing dataset: 82.88%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 82.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 82.62%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 82.39%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 82.52%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 82.31%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 82.33%\n",
      "Accuracy on this batch 95.31%\n",
      "Accuracy till now:  testing dataset: 82.76%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 82.66%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 82.62%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 82.39%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 82.49%\n",
      "Accuracy on this batch 93.75%\n",
      "Accuracy till now:  testing dataset: 82.81%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 82.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 82.85%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 82.81%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 82.85%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 82.77%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 82.70%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 82.70%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 82.70%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 82.71%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 82.71%\n",
      "Accuracy on this batch 68.75%\n",
      "Accuracy till now:  testing dataset: 82.40%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 82.35%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 82.42%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 82.27%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 82.25%\n",
      "Accuracy on this batch 70.31%\n",
      "Accuracy till now:  testing dataset: 82.02%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.94%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 82.02%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 82.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.88%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.78%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.84%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.89%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.85%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.84%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.80%\n",
      "Accuracy on this batch 92.19%\n",
      "Accuracy till now:  testing dataset: 81.97%\n",
      "Accuracy on this batch 71.88%\n",
      "Accuracy till now:  testing dataset: 81.81%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.71%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.75%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.72%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 81.80%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.75%\n",
      "Accuracy on this batch 92.19%\n",
      "Accuracy till now:  testing dataset: 81.90%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.91%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.97%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.89%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.84%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.90%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.81%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.80%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 81.87%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.78%\n",
      "Accuracy on this batch 70.31%\n",
      "Accuracy till now:  testing dataset: 81.64%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.60%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.63%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.68%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.69%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.61%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.61%\n",
      "Accuracy on this batch 73.44%\n",
      "Accuracy till now:  testing dataset: 81.52%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.50%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.44%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.46%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.50%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.54%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.53%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.56%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.53%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.54%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.52%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.48%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.45%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.39%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.34%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 67.19%\n",
      "Accuracy till now:  testing dataset: 81.19%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 81.25%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.26%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.29%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.31%\n",
      "Accuracy on this batch 73.44%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.25%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.21%\n",
      "Accuracy on this batch 90.62%\n",
      "Accuracy till now:  testing dataset: 81.29%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.33%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.32%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.29%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.31%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.31%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.29%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.29%\n",
      "Accuracy on this batch 73.44%\n",
      "Accuracy till now:  testing dataset: 81.23%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.19%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.23%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.27%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.23%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 81.29%\n",
      "Accuracy on this batch 84.38%\n",
      "Accuracy till now:  testing dataset: 81.31%\n",
      "Accuracy on this batch 71.88%\n",
      "Accuracy till now:  testing dataset: 81.24%\n",
      "Accuracy on this batch 79.69%\n",
      "Accuracy till now:  testing dataset: 81.23%\n",
      "Accuracy on this batch 89.06%\n",
      "Accuracy till now:  testing dataset: 81.28%\n",
      "Accuracy on this batch 68.75%\n",
      "Accuracy till now:  testing dataset: 81.19%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.17%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.17%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.13%\n",
      "Accuracy on this batch 85.94%\n",
      "Accuracy till now:  testing dataset: 81.16%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.14%\n",
      "Accuracy on this batch 76.56%\n",
      "Accuracy till now:  testing dataset: 81.11%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.09%\n",
      "Accuracy on this batch 73.44%\n",
      "Accuracy till now:  testing dataset: 81.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.05%\n",
      "Accuracy on this batch 75.00%\n",
      "Accuracy till now:  testing dataset: 81.01%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 81.05%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.03%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.01%\n",
      "Accuracy on this batch 82.81%\n",
      "Accuracy till now:  testing dataset: 81.02%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.02%\n",
      "Accuracy on this batch 87.50%\n",
      "Accuracy till now:  testing dataset: 81.07%\n",
      "Accuracy on this batch 89.06%\n",
      "Accuracy till now:  testing dataset: 81.12%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.12%\n",
      "Accuracy on this batch 78.12%\n",
      "Accuracy till now:  testing dataset: 81.10%\n",
      "Accuracy on this batch 81.25%\n",
      "Accuracy till now:  testing dataset: 81.10%\n",
      "\n",
      "number of tests: 157\n",
      "Accuracy on the testing dataset: 81.10%\n",
      "time taken to train :  11.49685287475586\n",
      "81.10000000000001\n",
      "data saved\n"
     ]
    }
   ],
   "source": [
    "# part 6 :\n",
    "# testing \n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate over the testing dataset\n",
    "\n",
    "k=0\n",
    "for inputs, labels in test_loader:  # Use your test data loader\n",
    "    k+=1\n",
    "    # Forward pass to obtain predictions\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Get the predicted class for each example in the batch\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    \n",
    "    # Count correct predictions in this batch\n",
    "    batch_correct_predictions = (predicted == labels).sum().item()\n",
    "    correct_predictions += batch_correct_predictions\n",
    "    \n",
    "    # Count total predictions in this batch\n",
    "\n",
    "    batch_total_predictions = labels.size(0)\n",
    "    total_predictions += batch_total_predictions \n",
    "\n",
    "    # Print the running accuracy for this batch\n",
    "    # Update running accuracy\n",
    "    batch_accuracy=batch_correct_predictions/batch_total_predictions * 100.0\n",
    "    print(f\"Accuracy on this batch {batch_accuracy:.2f}%\")\n",
    "\n",
    "    accuracy = (correct_predictions / total_predictions) * 100.0\n",
    "    print(f\"Accuracy till now:  testing dataset: {accuracy:.2f}%\")\n",
    "\n",
    "print()\n",
    "print(\"number of tests:\",k)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (correct_predictions / total_predictions) * 100.0\n",
    "print(f\"Accuracy on the testing dataset: {accuracy:.2f}%\")\n",
    "print('time taken to train : ',training_time)\n",
    "\n",
    "\n",
    "# saving accuracy\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "# tk\n",
    "# log_dir=\"../../log/\"\n",
    "# tunefilename=f'Accuracy {accuracy} ,pat{reduceLR_patience}, LRfac{reduceLR_factor},LR{learning_rate}'\n",
    "# plot_dir=log_dir\n",
    "# os.makedirs(plot_dir, exist_ok=True)\n",
    "# logfilename=tunefilename+'.log'\n",
    "# plotfilename=tunefilename+'.png'\n",
    "# plotfilename=f'pat{reduceLR_patience}, LRfac{reduceLR_factor},LR{learning_rate}.png'\n",
    "# plotfile=os.path.join(log_dir, plotfilename)\n",
    "# logfile=os.path.join(log_dir, logfilename)\n",
    "\n",
    "\n",
    "# tunefilename=f'patience={reduceLR_patience}_LR_factor={reduceLR_factor}'\n",
    "\n",
    "import logging\n",
    "\n",
    "# print(logfile)\n",
    "print(accuracy)\n",
    "# logging.basicConfig(filename=f'{accuracy}.log', level=logging.INFO, format='%(message)s')\n",
    "# logging.info(f\"initial learning rate : {learning_rate:.2f} | Accuracy: {accuracy:.2f}% | {num_epochs} epochs | converged : {converged}\\n\")\n",
    "# logging.info(\"ererer\")\n",
    "loginfo(accuracy)\n",
    "logging.shutdown()\n",
    "\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "# loginfo(converged,accuracy)\n",
    "print(\"data saved\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.552935,
   "end_time": "2023-09-08T22:37:26.659045",
   "environment_variables": {},
   "exception": null,
   "input_path": "c:\\Users\\pande\\OneDrive\\Desktop\\code\\ML\\ELL409-Machine-Learning-Coursework\\assignment-01\\code\\q1linear-classification\\a5.ipynb",
   "output_path": "c:\\Users\\pande\\OneDrive\\Desktop\\code\\ML\\ELL409-Machine-Learning-Coursework\\assignment-01\\code\\q1linear-classification\\a4out.ipynb",
   "parameters": {
    "learning_rate": 0.14,
    "reduceLR_factor": 0.6,
    "reduceLR_patience": 5,
    "weight_decay_rate": 0
   },
   "start_time": "2023-09-08T22:37:08.106110",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}