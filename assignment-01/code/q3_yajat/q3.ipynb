{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = 'saved_models'\n",
    "model_filename = 'linear_regression_model.pth'\n",
    "model_file_path = os.path.join(model_directory, model_filename)\n",
    "\n",
    "# Ensure the directory exists, create it if it doesn't\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "# Function to load or initialize the model\n",
    "def load_or_initialize_model(X_train, y_train):\n",
    "\n",
    "# Load the model if it exists, otherwise initialize a new model\n",
    "    if os.path.exists(model_file_path):\n",
    "        print('Model exist so using it')\n",
    "        model = torch.load(model_file_path)\n",
    "    else:\n",
    "        print('Model does not exist so initialising from scratch')\n",
    "        input_size = X_train.shape[1]\n",
    "        model = nn.Linear(input_size, 1).double()\n",
    "        torch.save(model, model_file_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeltrain(X_train,y_train):\n",
    "    input_size = X_train.shape[1]\n",
    "    model = nn.Linear(input_size, 1).double()  # Double data type for weight tensor\n",
    "\n",
    "# Define loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model (rest of the code remains the same)\n",
    "    num_epochs = 1000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "        outputs = model(X_train.double())  # Ensure input data type matches model's weight data type\n",
    "        loss = criterion(outputs, y_train.view(-1, 1))\n",
    "\n",
    "    # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "    \n",
    "\n",
    "\n",
    "    print('Training Done')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeltest(X_test,y_test,model):\n",
    "    print(\"Testing starting\")\n",
    "    # Assuming 'model' is your trained linear regression model\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)\n",
    "\n",
    "\n",
    "    print('testing over now accuracy analysis')\n",
    "\n",
    "    predictions = predictions.numpy()\n",
    "    y_test = y_test.numpy()  # Replace with actual ground truth if available\n",
    "\n",
    "    # Calculate MAE and MSE\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    print(f'MAE: {mae}')\n",
    "    print(f'MSE: {mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(X,y):\n",
    "    # Replace 'X1' with the name of the feature you want to plot.\n",
    "    n=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "    feature_to_plot = X[:,n] \n",
    "\n",
    "    # Create a scatter plotc.ear\n",
    "    plt.plot(feature_to_plot, y, alpha=0.5)\n",
    "    plt.xlabel('Feature No:')  # Replace with the appropriate feature name\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Line Plot of Feature vs. y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing of data\n",
    "\n",
    "\n",
    "df = pd.read_csv('assignment-01/code/q3_yajat/q3.py')\n",
    "#print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Separate the target variable 'y' from the input features.\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding.\n",
    "X = pd.get_dummies(X, columns=['X3'], prefix=['X3'])\n",
    "\n",
    "for column in X.columns:\n",
    "    try:\n",
    "        X[column] = X[column].astype(float)\n",
    "    except ValueError:\n",
    "        print(f\"Column '{column}' cannot be converted to float.\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a PyTorch tensor.\n",
    "X = torch.tensor(X.values, dtype=torch.float64)\n",
    "\n",
    "# Convert the target variable to a PyTorch tensor.\n",
    "y = torch.tensor(y.values, dtype=torch.float64)\n",
    "size=len(X)\n",
    "train_ratio=0.6\n",
    "train_size=int(size*train_ratio)\n",
    "test_size=size-train_size\n",
    "\n",
    "\n",
    "#Splitting the data in training and testing data \n",
    "\n",
    "\n",
    "#Training data\n",
    "X_train=X[:train_size]\n",
    "y_train=y[:train_size]\n",
    "\n",
    "#Testing data\n",
    "X_test=X[train_size:]\n",
    "y_test=y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "create_plot(X_train,y_train)\n",
    "model = load_or_initialize_model(X_train, y_train)\n",
    "model=modeltrain(X_train,y_train)\n",
    "modeltest(X_test,y_test,model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
