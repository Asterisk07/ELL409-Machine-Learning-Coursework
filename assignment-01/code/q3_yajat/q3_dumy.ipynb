{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all import statements\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_directory = 'saved_models'\n",
    "model_filename = 'linear_regression_model.pth'\n",
    "model_file_path = os.path.join(model_directory, model_filename)\n",
    "\n",
    "# Ensure the directory exists, create it if it doesn't\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "# Function to load or initialize the model\n",
    "def load_or_initialize_model(X_train, y_train):\n",
    "\n",
    "    # Load the model if it exists, otherwise initialize a new model\n",
    "    if os.path.exists(model_file_path):\n",
    "        print('Model exist so using it')\n",
    "        model = torch.load(model_file_path)\n",
    "    else:\n",
    "        print('Model does not exist so initialising from scratch')\n",
    "        input_size = X_train.shape[1]\n",
    "        model = nn.Linear(input_size, 1).double()\n",
    "        torch.save(model, model_file_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to train the model\n",
    "def modeltrain(X_train, y_train, l2_lambda=0.01):  # Specify the regularization strength (lambda)\n",
    "\n",
    "    input_size = X_train.shape[1]\n",
    "    model = nn.Linear(input_size, 1).double()  # Double data type for weight tensor\n",
    "\n",
    "    # Define loss function and optimizer with L2 regularization\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=l2_lambda)  # Adding weight decay for L2 regularization\n",
    "\n",
    "    # Train the model (rest of the code remains the same)\n",
    "    num_epochs = 1000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass\n",
    "        outputs = model(X_train.double())  # Ensure input data type matches model's weight data type\n",
    "        loss = criterion(outputs, y_train.view(-1, 1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "    print('Training Done')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to test the model\n",
    "def modeltest(X_test,y_test,model):\n",
    "    print(\"Testing starting\")\n",
    "    # Assuming 'model' is your trained linear regression model\n",
    "    # print(model)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test)\n",
    "\n",
    "\n",
    "    print('testing over now accuracy analysis')\n",
    "    # print(predictions)\n",
    "    correct_pred=0\n",
    "    for i in range(len(predictions)):\n",
    "        if(abs(predictions[i]-y_test[i])<0.1):\n",
    "            correct_pred+=1\n",
    "    mean_accuracy=(correct_pred/len(predictions))*100\n",
    "    print(f'Percentage Accuracy: {mean_accuracy:.2f}%')\n",
    "\n",
    "    # Calculate MAE and MSE\n",
    "    # mae = mean_absolute_error(y_test, predictions)\n",
    "    # mse = mean_squared_error(y_test, predictions)\n",
    "\n",
    "    # print(f'MAE: {mae}')\n",
    "    # print(f'MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_plot(X,y):\n",
    "    # Replace 'X1' with the name of the feature you want to plot.\n",
    "    # n=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "    # n1=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "    # n2=int(input(\"Enter the feature for which you want the plot, enter any value b/w 0-2:\"))\n",
    "\n",
    "    feature_to_plot = X[:,0] \n",
    "    feature_to_plot1 = X[:,1] \n",
    "    feature_to_plot2 = X[:,2] \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Create a scatter plotc.ear\n",
    "    # plt.scatter(feature_to_plot, y, alpha=0.5)\n",
    "    # plt.show()\n",
    "    plt.scatter(feature_to_plot1, y, alpha=0.5)\n",
    "    # plt.show()\n",
    "    plt.scatter(feature_to_plot2, y, alpha=0.5)\n",
    "\n",
    "    # plt.plot(feature_to_plot, y, alpha=0.5)  #line plot\n",
    "    plt.xlabel('Feature No:')  # Replace with the appropriate feature name\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Line Plot of Feature vs. y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Data  proccessing and normalisation tried\n",
    "\n",
    "df = pd.read_csv('Q3_complex_linear_regression_dataset.csv')\n",
    "#print(df.head())\n",
    "\n",
    "\n",
    "\n",
    "# Separate the target variable 'y' from the input features.\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding.\n",
    "X = pd.get_dummies(X, columns=['X3'], prefix=['X3'])\n",
    "\n",
    "for column in X.columns:\n",
    "    try:\n",
    "        X[column] = X[column].astype(float)\n",
    "    except ValueError:\n",
    "        print(f\"Column '{column}' cannot be converted to float.\")\n",
    "\n",
    "\n",
    "\n",
    "# Convert the DataFrame to a PyTorch tensor.\n",
    "X = torch.tensor(X.values, dtype=torch.float64)\n",
    "list_X1=[]\n",
    "listd=[]\n",
    "for i in range(len(X)):\n",
    "    list_X1.append(X[i][0].item())\n",
    "    listd.append([X[i][0].item(),X[i][1].item(),X[i][2].item()])\n",
    "\n",
    "\n",
    "# print(list_X1)\n",
    "list_X1=torch.tensor(list_X1)\n",
    "mean_X1 = torch.mean(list_X1).item()\n",
    "std_X1 = torch.std(list_X1).item()\n",
    "# print(mean_X1.item(),std_X1.item())\n",
    "\n",
    "for i in range(len(X)):\n",
    "    listd[i][0]=(listd[i][0]-mean_X1)/std_X1\n",
    "listd=torch.tensor(listd)\n",
    "# print(\"X befor normalisation\",X)\n",
    "# X=listd\n",
    "# print('X after normalsation',X)\n",
    "\n",
    "# Convert the target variable to a PyTorch tensor.\n",
    "y = torch.tensor(y.values, dtype=torch.float64)\n",
    "size=len(X)\n",
    "train_ratio=0.7\n",
    "train_size=int(size*train_ratio)\n",
    "test_size=size-train_size\n",
    "\n",
    "\n",
    "#Splitting the data in training and testing data \n",
    "\n",
    "\n",
    "#Training data\n",
    "X_train=X[:train_size]\n",
    "y_train=y[:train_size]\n",
    "\n",
    "#Testing data\n",
    "X_test=X[train_size:]\n",
    "y_test=y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance between input1 and input2: 0.12740488844015435\n",
      "Covariance between input2 and input3: -0.025787961695156975\n",
      "Covariance between input3 and input2: 0.012576896787423134\n"
     ]
    }
   ],
   "source": [
    "#Relation of input variables with each other (EDA)\n",
    "input1=[]\n",
    "input2=[]\n",
    "input3=[]\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    c=X_train[i][0]\n",
    "\n",
    "    input1.append(c.item())\n",
    "    c=X_train[i][1]\n",
    "\n",
    "    input2.append(c.item())\n",
    "    c=X_train[i][2]\n",
    "    input3.append(c.item())\n",
    "\n",
    "covariance_matrix = np.cov(input1, input2)\n",
    "\n",
    "# Extract the covariance between the two variables from the covariance matrix\n",
    "covariance = covariance_matrix[0, 1]\n",
    "\n",
    "# print(\"Covariance between input1 and input2:\", covariance)\n",
    "\n",
    "covariance_matrix1 = np.cov(input1, input3)\n",
    "covariance_matrix2 = np.cov(input3, input2)\n",
    "covariance1 = covariance_matrix1[0, 1]\n",
    "covariance2 = covariance_matrix2[0, 1]\n",
    "print(\"Covariance between input1 and input2:\", covariance)\n",
    "print(\"Covariance between input2 and input3:\", covariance1)\n",
    "print(\"Covariance between input3 and input2:\", covariance2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exist so using it\n",
      "Epoch [100/1000], Loss: 4.301497218940662\n",
      "Epoch [200/1000], Loss: 4.082559691224999\n",
      "Epoch [300/1000], Loss: 3.980664250626326\n",
      "Epoch [400/1000], Loss: 3.9324987828207263\n",
      "Epoch [500/1000], Loss: 3.9093966933480933\n",
      "Epoch [600/1000], Loss: 3.898126532153832\n",
      "Epoch [700/1000], Loss: 3.892511088415876\n",
      "Epoch [800/1000], Loss: 3.8896389564283114\n",
      "Epoch [900/1000], Loss: 3.888123444225567\n",
      "Epoch [1000/1000], Loss: 3.8872952420303215\n",
      "Training Done\n",
      "Testing starting\n",
      "testing over now accuracy analysis\n",
      "Percentage Accuracy: 4.44%\n"
     ]
    }
   ],
   "source": [
    "# create_plot(X_train,y_train)\n",
    "# model = load_or_initialize_model(X_train, y_train)\n",
    "# model=modeltrain(X_train,y_train)\n",
    "model = load_or_initialize_model(X_train,y_train)\n",
    "model = modeltrain(X_train, y_train, l2_lambda=0.01)  # You can adjust the regularization st\n",
    "modeltest(X_test,y_test,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
