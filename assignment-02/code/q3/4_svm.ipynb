{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from cvxopt import matrix, solvers\n",
    "merged_data = pd.read_csv('../../data/merged_data_truncated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 8)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Sentiment1</th>\n",
       "      <th>Sentiment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.800003</td>\n",
       "      <td>177.990005</td>\n",
       "      <td>173.179993</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>57224100</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.096352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176.809998</td>\n",
       "      <td>179.050003</td>\n",
       "      <td>175.800003</td>\n",
       "      <td>178.990005</td>\n",
       "      <td>178.990005</td>\n",
       "      <td>42390800</td>\n",
       "      <td>-0.2204</td>\n",
       "      <td>0.071875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.100006</td>\n",
       "      <td>179.720001</td>\n",
       "      <td>177.949997</td>\n",
       "      <td>178.389999</td>\n",
       "      <td>178.389999</td>\n",
       "      <td>43698000</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.170134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178.199997</td>\n",
       "      <td>179.850006</td>\n",
       "      <td>177.600006</td>\n",
       "      <td>179.800003</td>\n",
       "      <td>179.800003</td>\n",
       "      <td>47551100</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.143628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.070007</td>\n",
       "      <td>182.339996</td>\n",
       "      <td>179.039993</td>\n",
       "      <td>180.710007</td>\n",
       "      <td>180.710007</td>\n",
       "      <td>56743100</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.106639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close   Adj Close    Volume  \\\n",
       "0  173.800003  177.990005  173.179993  177.490005  177.490005  57224100   \n",
       "1  176.809998  179.050003  175.800003  178.990005  178.990005  42390800   \n",
       "2  178.100006  179.720001  177.949997  178.389999  178.389999  43698000   \n",
       "3  178.199997  179.850006  177.600006  179.800003  179.800003  47551100   \n",
       "4  180.070007  182.339996  179.039993  180.710007  180.710007  56743100   \n",
       "\n",
       "   Sentiment1  Sentiment2  \n",
       "0      0.9480    0.096352  \n",
       "1     -0.2204    0.071875  \n",
       "2      0.9768    0.170134  \n",
       "3      0.9854    0.143628  \n",
       "4      0.9934    0.106639  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# y_open=merged_data['Open']\n",
    "# y_close=merged_data['Close']\n",
    "y_data=merged_data.drop(columns=['High','Low','Adj Close','Volume','Sentiment1','Sentiment2'])\n",
    "# print(y_data)\n",
    "# y_array=y_data.values\n",
    "# print(y_array)\n",
    "input_vector= merged_data.drop(columns=['Open','Close','Adj Close'])\n",
    "# input_array = input_vector.values\n",
    "size=len(input_vector)\n",
    "print(size)\n",
    "train_ratio=0.6\n",
    "train_size=int(size*train_ratio)\n",
    "    \n",
    "\n",
    "\n",
    "# #Splitting the data in training and testing data \n",
    "\n",
    "\n",
    "#Training data\n",
    "X_train=input_vector[:train_size]\n",
    "# print(X_train)\n",
    "y_train=y_data[:train_size]\n",
    "    \n",
    "#Testing data\n",
    "\n",
    "X_test=input_vector[train_size:]\n",
    "y_test=y_data[train_size:]\n",
    "\n",
    "#Conversion from pandas data frame to numpy data frame\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "# print(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(x1, x2, gamma='scale'):\n",
    "      # If gamma is set to 'scale', calculate it based on the number of features in x1\n",
    "    if gamma == 'scale':\n",
    "        gamma = 1 / (2 * len(x1))\n",
    "    #this is the radial basis kernel evaluation based on norm\n",
    "    return np.exp(-gamma * np.linalg.norm(x1 - x2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kernel_matrix(X, gamma='scale'):\n",
    "    n_samples = X.shape[0]\n",
    "    kernel_matrix = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            kernel_matrix[i, j] = rbf_kernel(X[i], X[j], gamma)\n",
    "    return kernel_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_svr(X, y, C=1.0, epsilon=0.1, gamma='scale'):\n",
    "#     n_samples, n_features = X.shape\n",
    "\n",
    "#     # Calculate the kernel matrix\n",
    "#     kernel_matrix = calculate_kernel_matrix(X, gamma)\n",
    "\n",
    "#     # Quadratic programming problem (simplified)\n",
    "#     P = np.outer(y, y) * kernel_matrix\n",
    "#     q = -np.ones(n_samples)\n",
    "#     G = np.vstack([-np.eye(n_samples), np.eye(n_samples)])\n",
    "#     h = np.hstack([np.zeros(n_samples), np.ones(n_samples) * C])\n",
    "\n",
    "#     # Solve the optimization problem (you may replace this with a more advanced solver)\n",
    "#     # solution = np.linalg.solve(P, q, G, h)\n",
    "#     solution = solvers.qp(P, q, G, h)\n",
    "\n",
    "#     # Extract weights, intercept, and support vectors\n",
    "#     alpha = solution[:n_samples]\n",
    "#     sv_indices = np.where(alpha > 1e-5)[0]\n",
    "#     support_vectors_X = X[sv_indices]\n",
    "#     support_vectors_y = y[sv_indices]\n",
    "#     support_vectors_alpha = alpha[sv_indices]\n",
    "\n",
    "#     # Calculate weights and intercept\n",
    "#     weights = np.sum(support_vectors_alpha * support_vectors_y[:, None] *\n",
    "#                      np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X.values]), axis=0)\n",
    "#     intercept = np.mean(support_vectors_y - np.dot(weights, support_vectors_X.values.T))\n",
    "\n",
    "#     return weights, intercept, {'X': support_vectors_X, 'y': support_vectors_y, 'alpha': support_vectors_alpha}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cvxopt import matrix, solvers\n",
    "\n",
    "def train_svr(X, y, C=1.0, epsilon=0.1, gamma='scale'):\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Calculate the kernel matrix\n",
    "    kernel_matrix = calculate_kernel_matrix(X, gamma)\n",
    "\n",
    "    # Quadratic programming problem (simplified)\n",
    "    P = matrix(np.outer(y.flatten(), y.flatten()) * kernel_matrix)\n",
    "    q = matrix(-np.ones(n_samples))\n",
    "    G = matrix(np.vstack([-np.eye(n_samples), np.eye(n_samples)]))\n",
    "    h = matrix(np.hstack([np.zeros(n_samples), np.ones(n_samples) * C]))\n",
    "\n",
    "    # Solve the optimization problem using cvxopt\n",
    "    sol = solvers.qp(P, q, G, h)\n",
    "\n",
    "    # Extract Lagrange multipliers\n",
    "    alpha = np.array(sol['x']).flatten()\n",
    "\n",
    "    # Extract support vectors\n",
    "    sv_indices = np.where(alpha > 1e-5)[0]\n",
    "    support_vectors_X = X[sv_indices]\n",
    "    support_vectors_y = y[sv_indices]\n",
    "    support_vectors_alpha = alpha[sv_indices]\n",
    "\n",
    "# Calculate weights and intercept\n",
    "    weights = np.sum(support_vectors_alpha[:, None, None] *\n",
    "                support_vectors_y[:, :, None] *\n",
    "                np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X]), axis=0)\n",
    "\n",
    "    intercept = np.mean(support_vectors_y - np.sum(weights * np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X]), axis=0))\n",
    "\n",
    "    return weights, intercept, {'X': support_vectors_X, 'y': support_vectors_y, 'alpha': support_vectors_alpha} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svr(X_test, weights, intercept, support_vectors, gamma='scale'):\n",
    "    predictions = np.dot(weights, np.array([rbf_kernel(x, support_vectors['X'], gamma) for x in X_test]).T) + intercept\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0491e-08 -1.0001e+01  1e+01  4e-17  2e-16\n",
      " 1: -1.4283e-04 -1.0028e-01  1e-01  2e-16  4e-16\n",
      " 2: -1.5894e-04 -1.1673e-03  1e-03  2e-16  6e-17\n",
      " 3: -1.5905e-04 -1.6914e-04  1e-05  2e-16  4e-17\n",
      " 4: -1.5905e-04 -1.5915e-04  1e-07  2e-16  5e-17\n",
      " 5: -1.5905e-04 -1.5905e-04  1e-09  2e-16  7e-17\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,10) and (7,) not aligned: 10 (dim 1) != 7 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m weights, intercept, support_vectors \u001b[39m=\u001b[39mtrain_svr(X_train, y_train, C\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, epsilon\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, gamma\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred\u001b[39m=\u001b[39mpredict_svr(X_test,weights,intercept,support_vectors)\n",
      "\u001b[1;32m/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_svr\u001b[39m(X_test, weights, intercept, support_vectors, gamma\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     predictions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(weights, np\u001b[39m.\u001b[39;49marray([rbf_kernel(x, support_vectors[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m], gamma) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m X_test])\u001b[39m.\u001b[39;49mT) \u001b[39m+\u001b[39m intercept\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yajatkapoor/Desktop/ELL409-Machine-Learning-Coursework/ELL409-Machine-Learning-Coursework/assignment-02/code/q3/4_svm.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,10) and (7,) not aligned: 10 (dim 1) != 7 (dim 0)"
     ]
    }
   ],
   "source": [
    "weights, intercept, support_vectors =train_svr(X_train, y_train, C=1.0, epsilon=0.1, gamma='scale')\n",
    "y_pred=predict_svr(X_test,weights,intercept,support_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(y_test,y_pred):\n",
    "    # y_true = y_test  # Replace true_values with the actual values from your dataset\n",
    "    # y_pred = predict_svr(X_test, weights, intercept, support_vectors, gamma)\n",
    "\n",
    "# Calculate the mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Calculate the mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# Calculate the R-squared (R2) score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R-squared (R2) Score: {r2}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
