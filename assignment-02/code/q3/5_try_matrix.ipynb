{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from cvxopt import matrix, solvers\n",
    "merged_data = pd.read_csv('../../data/merged_data_truncated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Sentiment1</th>\n",
       "      <th>Sentiment2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173.800003</td>\n",
       "      <td>177.990005</td>\n",
       "      <td>173.179993</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>177.490005</td>\n",
       "      <td>57224100</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.096352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176.809998</td>\n",
       "      <td>179.050003</td>\n",
       "      <td>175.800003</td>\n",
       "      <td>178.990005</td>\n",
       "      <td>178.990005</td>\n",
       "      <td>42390800</td>\n",
       "      <td>-0.2204</td>\n",
       "      <td>0.071875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.100006</td>\n",
       "      <td>179.720001</td>\n",
       "      <td>177.949997</td>\n",
       "      <td>178.389999</td>\n",
       "      <td>178.389999</td>\n",
       "      <td>43698000</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.170134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>178.199997</td>\n",
       "      <td>179.850006</td>\n",
       "      <td>177.600006</td>\n",
       "      <td>179.800003</td>\n",
       "      <td>179.800003</td>\n",
       "      <td>47551100</td>\n",
       "      <td>0.9854</td>\n",
       "      <td>0.143628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.070007</td>\n",
       "      <td>182.339996</td>\n",
       "      <td>179.039993</td>\n",
       "      <td>180.710007</td>\n",
       "      <td>180.710007</td>\n",
       "      <td>56743100</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>0.106639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open        High         Low       Close   Adj Close    Volume  \\\n",
       "0  173.800003  177.990005  173.179993  177.490005  177.490005  57224100   \n",
       "1  176.809998  179.050003  175.800003  178.990005  178.990005  42390800   \n",
       "2  178.100006  179.720001  177.949997  178.389999  178.389999  43698000   \n",
       "3  178.199997  179.850006  177.600006  179.800003  179.800003  47551100   \n",
       "4  180.070007  182.339996  179.039993  180.710007  180.710007  56743100   \n",
       "\n",
       "   Sentiment1  Sentiment2  \n",
       "0      0.9480    0.096352  \n",
       "1     -0.2204    0.071875  \n",
       "2      0.9768    0.170134  \n",
       "3      0.9854    0.143628  \n",
       "4      0.9934    0.106639  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# y_open=merged_data['Open']\n",
    "# y_close=merged_data['Close']\n",
    "y_data=merged_data.drop(columns=['High','Low','Adj Close','Volume','Sentiment1','Sentiment2','Close'])\n",
    "# print(y_data)\n",
    "# y_array=y_data.values\n",
    "# print(y_array)\n",
    "input_vector= merged_data.drop(columns=['Open','Close','Adj Close'])\n",
    "# input_array = input_vector.values\n",
    "size=len(input_vector)\n",
    "print(size)\n",
    "train_ratio=0.6\n",
    "train_size=int(size*train_ratio)\n",
    "    \n",
    "\n",
    "\n",
    "# #Splitting the data in training and testing data \n",
    "\n",
    "\n",
    "#Training data\n",
    "X_train=input_vector[:train_size]\n",
    "# print(X_train)\n",
    "y_train=y_data[:train_size]\n",
    "    \n",
    "#Testing data\n",
    "\n",
    "X_test=input_vector[train_size:]\n",
    "y_test=y_data[train_size:]\n",
    "\n",
    "#Conversion from pandas data frame to numpy data frame\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "# print(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(x1, x2, gamma='scale'):\n",
    "      # If gamma is set to 'scale', calculate it based on the number of features in x1\n",
    "    if gamma == 'scale':\n",
    "        gamma = 1 / (2 * len(x1))\n",
    "    #this is the radial basis kernel evaluation based on norm\n",
    "    return np.exp(-gamma * np.linalg.norm(x1 - x2) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kernel_matrix(X, gamma='scale'):\n",
    "    n_samples = X.shape[0]\n",
    "    kernel_matrix = np.zeros((n_samples, n_samples))\n",
    "    for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "            kernel_matrix[i, j] = rbf_kernel(X[i], X[j], gamma)\n",
    "    return kernel_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_svr(X, y, C=1.0, epsilon=0.1, gamma='scale'):\n",
    "#     n_samples, n_features = X.shape\n",
    "\n",
    "#     # Calculate the kernel matrix\n",
    "#     kernel_matrix = calculate_kernel_matrix(X, gamma)\n",
    "\n",
    "#     # Quadratic programming problem (simplified)\n",
    "#     P = np.outer(y, y) * kernel_matrix\n",
    "#     q = -np.ones(n_samples)\n",
    "#     G = np.vstack([-np.eye(n_samples), np.eye(n_samples)])\n",
    "#     h = np.hstack([np.zeros(n_samples), np.ones(n_samples) * C])\n",
    "\n",
    "#     # Solve the optimization problem (you may replace this with a more advanced solver)\n",
    "#     # solution = np.linalg.solve(P, q, G, h)\n",
    "#     solution = solvers.qp(P, q, G, h)\n",
    "\n",
    "#     # Extract weights, intercept, and support vectors\n",
    "#     alpha = solution[:n_samples]\n",
    "#     sv_indices = np.where(alpha > 1e-5)[0]\n",
    "#     support_vectors_X = X[sv_indices]\n",
    "#     support_vectors_y = y[sv_indices]\n",
    "#     support_vectors_alpha = alpha[sv_indices]\n",
    "\n",
    "#     # Calculate weights and intercept\n",
    "#     weights = np.sum(support_vectors_alpha * support_vectors_y[:, None] *\n",
    "#                      np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X.values]), axis=0)\n",
    "#     intercept = np.mean(support_vectors_y - np.dot(weights, support_vectors_X.values.T))\n",
    "\n",
    "#     return weights, intercept, {'X': support_vectors_X, 'y': support_vectors_y, 'alpha': support_vectors_alpha}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from cvxopt import matrix, solvers\n",
    "\n",
    "# def train_svr(X, y, C=1.0, epsilon=0.1, gamma='scale'):\n",
    "#     n_samples, n_features = X.shape\n",
    "\n",
    "#     # Calculate the kernel matrix\n",
    "#     kernel_matrix = calculate_kernel_matrix(X, gamma)\n",
    "\n",
    "#     # Quadratic programming problem (simplified)\n",
    "#     P = matrix(np.outer(y.flatten(), y.flatten()) * kernel_matrix)\n",
    "#     q = matrix(-np.ones(n_samples))\n",
    "#     G = matrix(np.vstack([-np.eye(n_samples), np.eye(n_samples)]))\n",
    "#     h = matrix(np.hstack([np.zeros(n_samples), np.ones(n_samples) * C]))\n",
    "\n",
    "#     # Solve the optimization problem using cvxopt\n",
    "#     sol = solvers.qp(P, q, G, h)\n",
    "\n",
    "#     # Extract Lagrange multipliers\n",
    "#     alpha = np.array(sol['x']).flatten()\n",
    "\n",
    "#     # Extract support vectors\n",
    "#     sv_indices = np.where(alpha > 1e-5)[0]\n",
    "#     support_vectors_X = X[sv_indices]\n",
    "#     support_vectors_y = y[sv_indices]\n",
    "#     support_vectors_alpha = alpha[sv_indices]\n",
    "\n",
    "# # Calculate weights and intercept\n",
    "#     weights = np.sum(support_vectors_alpha[:, None, None] *\n",
    "#                 support_vectors_y[:, :, None] *\n",
    "#                 np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X]), axis=0)\n",
    "\n",
    "#     intercept = np.mean(support_vectors_y - np.sum(weights * np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X]), axis=0))\n",
    "\n",
    "#     return weights, intercept, {'X': support_vectors_X, 'y': support_vectors_y, 'alpha': support_vectors_alpha} \n",
    "\n",
    "\n",
    "# from cvxopt import matrix, solvers\n",
    "P,q,G,h=0,0,0,0\n",
    "\n",
    "def train_svr(X, y, C=1.0, epsilon=0.1, gamma='scale'):\n",
    "    global P,q,G,h\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Normalize input features if needed\n",
    "\n",
    "    # Calculate the kernel matrix\n",
    "    kernel_matrix = calculate_kernel_matrix(X, gamma)\n",
    "\n",
    "    # Quadratic programming problem (simplified)\n",
    "    P = matrix(np.outer(y.flatten(), y.flatten()) * kernel_matrix)\n",
    "    q = matrix(-np.ones(n_samples))\n",
    "    G = matrix(np.vstack([-np.eye(n_samples), np.eye(n_samples)]))\n",
    "    h = matrix(np.hstack([np.zeros(n_samples), np.ones(n_samples) * C]))\n",
    "\n",
    "    # Solve the optimization problem using cvxopt\n",
    "    sol = solvers.qp(P, q, G, h)\n",
    "\n",
    "    # Extract Lagrange multipliers\n",
    "    alpha = np.array(sol['x']).flatten()\n",
    "\n",
    "    # Extract support vectors\n",
    "    sv_indices = np.where(alpha > 1e-5)[0]\n",
    "    support_vectors_X = X[sv_indices]\n",
    "    support_vectors_y = y[sv_indices]\n",
    "    support_vectors_alpha = alpha[sv_indices]\n",
    "\n",
    "    # Calculate weights and intercept\n",
    "    weights = np.sum(support_vectors_alpha[:, None, None] *\n",
    "                     support_vectors_y[:, :, None] *\n",
    "                     np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X]), axis=0)\n",
    "\n",
    "    intercept = np.mean(support_vectors_y - np.sum(weights * np.array([rbf_kernel(x, support_vectors_X, gamma) for x in X]), axis=0))\n",
    "\n",
    "    return weights, intercept, {'X': support_vectors_X, 'y': support_vectors_y, 'alpha': support_vectors_alpha}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svr(X_test, weights, intercept, support_vectors, gamma='scale'):\n",
    "    \n",
    "    kernel_values = np.array([rbf_kernel(x, support_vectors['X'], gamma) for x in X_test])\n",
    "    print(type(weights))\n",
    "    print(type(kernel_values))\n",
    "    kernel_values = kernel_values.reshape(1, -1)\n",
    "    weights = weights.T\n",
    "\n",
    "    # Perform the dot product and add the intercept\n",
    "    predictions = np.dot(weights, kernel_values) + intercept\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights, intercept, support_vectors =train_svr(X_train, y_train, C=1.0, epsilon=0.1, gamma='scale')\n",
    "# y_pred=predict_svr(X_test,weights,intercept,support_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(y_test,y_pred):\n",
    "    # y_true = y_test  # Replace true_values with the actual values from your dataset\n",
    "    # y_pred = predict_svr(X_test, weights, intercept, support_vectors, gamma)\n",
    "    # print(y_pred)\n",
    "    # print(y_test)\n",
    "# Calculate the mean squared error (MSE)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# Calculate the mean absolute error (MAE)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# Calculate the R-squared (R2) score\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'R-squared (R2) Score: {r2}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -4.0491e-08 -1.0001e+01  1e+01  4e-17  3e-16\n",
      " 1: -1.4283e-04 -1.0028e-01  1e-01  2e-16  5e-16\n",
      " 2: -1.5894e-04 -1.1673e-03  1e-03  2e-16  6e-17\n",
      " 3: -1.5905e-04 -1.6914e-04  1e-05  2e-16  1e-16\n",
      " 4: -1.5905e-04 -1.5915e-04  1e-07  2e-16  1e-16\n",
      " 5: -1.5905e-04 -1.5905e-04  1e-09  2e-16  1e-16\n",
      "Optimal solution found.\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "weights, intercept, support_vectors =train_svr(X_train, y_train, C=1.0, epsilon=0.1, gamma='scale')\n",
    "y_pred=predict_svr(X_test,weights,intercept,support_vectors)\n",
    "# y_pred=y_pred[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([173.05000305])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test.shape\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 45.7778908217936\n",
      "Mean Absolute Error (MAE): 6.277712358747221\n",
      "R-squared (R2) Score: -6.188492638766343\n"
     ]
    }
   ],
   "source": [
    "analysis(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177.34199982, 177.34199982, 177.34199982, 177.34199982,\n",
       "       177.34199982, 177.34199982, 177.34199982])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177.34199982, 177.34199982, 177.34199982, 177.34199982,\n",
       "       177.34199982, 177.34199982, 177.34199982])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([177.34199982, 177.34199982, 177.34199982, 177.34199982,\n",
       "       177.34199982, 177.34199982, 177.34199982])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape\n",
    "y_pred.shape\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Assuming merged_data has columns like 'Date', 'Adj Close', 'Open', 'News_Sentiment', and other relevant features\n",
    "# features = merged_data[['High', 'Low', 'Volume','Sentiment1','Sentiment2']]  # Adjust features accordingly\n",
    "# # target = merged_data[['Open','Close']]  # Assuming you have a column 'Next_Day_Adj_Close'\n",
    "# target = merged_data['Close']\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# def rbf_kernel(X1, X2, gamma='auto'):\n",
    "#     if gamma == 'auto':\n",
    "#         # gamma = 1 / len(X1[0])\n",
    "#         gamma = 1 / X1.shape[0]\n",
    "#     return np.exp(-gamma * np.linalg.norm(X1 - X2) ** 2)\n",
    "\n",
    "# def fit_svr(X, y, kernel='rbf', C=1.0, epsilon=0.1, gamma='auto'):\n",
    "#     n_samples, n_features = X.shape\n",
    "\n",
    "#     # Compute the kernel matrix\n",
    "#     kernel_matrix = np.zeros((n_samples, n_samples))\n",
    "#     for i in range(n_samples):\n",
    "#         for j in range(n_samples):\n",
    "#             if kernel == 'rbf':\n",
    "#                 kernel_matrix[i, j] = rbf_kernel(X[i], X[j], gamma)\n",
    "\n",
    "#     # Quadratic programming problem to solve the dual problem\n",
    "#     P = np.outer(y, y) * kernel_matrix\n",
    "#     q = -np.ones(n_samples)\n",
    "#     G = np.vstack((-np.eye(n_samples), np.eye(n_samples)))\n",
    "#     h = np.hstack((np.zeros(n_samples), np.ones(n_samples) * C))\n",
    "\n",
    "#     # Solve the quadratic programming problem\n",
    "#     alpha = np.linalg.solve(P, q)\n",
    "\n",
    "#     # Extract support vectors\n",
    "#     sv_indices = alpha > 1e-5\n",
    "#     support_vectors = X[sv_indices]\n",
    "#     support_vector_labels = y[sv_indices]\n",
    "\n",
    "#     # Calculate weights and bias\n",
    "#     weights = np.sum(alpha[sv_indices][:, np.newaxis] * support_vector_labels[:, np.newaxis] * support_vectors, axis=0)\n",
    "#     bias = np.mean(support_vector_labels - np.dot(support_vectors, weights))\n",
    "\n",
    "#     return support_vectors, support_vector_labels, weights, bias\n",
    "\n",
    "# # def predict_svr(X, support_vectors, weights, bias, kernel='rbf', gamma='auto'):\n",
    "# #     if kernel == 'rbf':\n",
    "# #         kernel_values = np.array([rbf_kernel(X, sv, gamma) for sv in support_vectors])\n",
    "# #     else:\n",
    "# #         kernel_values = np.dot(X, support_vectors.T)\n",
    "\n",
    "# #     return np.dot(kernel_values, weights) + bias\n",
    "# def predict_svr(X, support_vectors, weights, bias, kernel='rbf', gamma='auto'):\n",
    "#     if kernel == 'rbf':\n",
    "#         kernel_values = np.array([rbf_kernel(X_i, sv, gamma) for X_i in X for sv in support_vectors])\n",
    "#     else:\n",
    "#         kernel_values = np.dot(X, support_vectors.T)\n",
    "\n",
    "#     return np.dot(kernel_values, weights) + bias\n",
    "\n",
    "# # Usage:\n",
    "# support_vectors, sv_labels, sv_weights, sv_bias = fit_svr(X_train.values, y_train.values)\n",
    "# y_pred = predict_svr(X_test.values, support_vectors, sv_weights, sv_bias)\n",
    "\n",
    "# def analysis(y_test,y_pred):\n",
    "#     # y_true = y_test  # Replace true_values with the actual values from your dataset\n",
    "#     # y_pred = predict_svr(X_test, weights, intercept, support_vectors, gamma)\n",
    "\n",
    "# # Calculate the mean squared error (MSE)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# # Calculate the mean absolute error (MAE)\n",
    "#     mae = mean_absolute_error(y_test, y_pred)\n",
    "#     print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# # Calculate the R-squared (R2) score\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "#     print(f'R-squared (R2) Score: {r2}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
